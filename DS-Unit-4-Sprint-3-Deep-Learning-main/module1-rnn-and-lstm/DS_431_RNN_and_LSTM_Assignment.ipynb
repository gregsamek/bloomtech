{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ryanleeallred/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nbsDADwcqLJ"
   },
   "source": [
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "The French mathematician Emile Borel once mused that [**infinite monkeys typing for an infinite amount of time**](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type the complete works of William Shakespeare. Let's see if we can get there a bit faster, with the power of **Recurrent Neural Networks and LSTMs**!\n",
    "\n",
    "Our goal in this projectis to build a **Shakespeare Sonnet Generator**.<br>\n",
    "Given a prompt of a few words as input, its task is to generate follow-on text that reads like a Shakespeare Sonnet!<br>\n",
    "\n",
    "To build our Sonnet Generator we will use a type of model called a **sequence model**. Given a short sequence, a sequence  model predicts the **most likely next item in the sequence**. Sequence models are astonishingly versatile and powerful, because the **sequence** we want to predict can be quite general! It can be composed of **words**, or of **characters**, or of **musical notes**, or of data points in a **time series** such as EKG voltages, or stock prices, or even a sequence of **DNA nucleotides**! \n",
    "\n",
    "We will train our model on the entire corpus of Shakespeare's Sonnets, and the model will learn from that data the most likely patterns of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2805,
     "status": "ok",
     "timestamp": 1639352765337,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "L-AX4IBIcqLK",
    "outputId": "dd11669c-bb6d-4939-b2d3-76f595bd76f2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import a custom text data preparation class\n",
    "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py\n",
    "from data_cleaning_toolkit_class import data_cleaning_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db6enoAacqLL"
   },
   "source": [
    "### Use `request` to pull data from a URL\n",
    "\n",
    "[**Read through the request documentation**](https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request) to learn how to download the Shakespeare Sonnets from the Gutenberg website. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1639352784538,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "nMf2XrJbcqLM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ac79c2e9a53d747ebf8fb41f4b39340",
     "grade": false,
     "grade_id": "cell-b8ececfad1f60557",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download all of Shakespeare's Sonnets from the Project Gutenberg website\n",
    "\n",
    "# here's the link for the sonnets\n",
    "url_shakespeare_sonnets = \"https://www.gutenberg.org/cache/epub/1041/pg1041.txt\"\n",
    "\n",
    "# use requests and the url to download all of the sonnets - save the result to `data`\n",
    "data = requests.get(url_shakespeare_sonnets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1639353327081,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "dcXTQ5RTcqLM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ab4f4f14188a9f3703d43d223bfa150",
     "grade": false,
     "grade_id": "cell-0cd0c8509bc8e8cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the downloaded text from the requests object and save it to `raw_text_data`\n",
    "# hint: take a look at the attributes of `data`\n",
    "# YOUR CODE HERE\n",
    "raw_text_data = data.text\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1639353365523,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "pW4mj8eScqLN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the data type of `raw_text_data`\n",
    "assert(type(raw_text_data)==str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwAX_OwEcqLN"
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1639352955648,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "4j7G1zqncqLO",
    "outputId": "8fb75f35-db3e-4afa-9ff9-0a6e10a7e34e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeff\\r\\n    The Project Gutenberg eBook of Shakespeare's Sonnets\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the United States and \\r\\nmost other parts of the world at no cost and with almost no restrictions \\r\\nwhatsoever. You may copy it, give it away or re-use it under the terms \\r\\nof the Project Gutenberg License included with this ebook or online \\r\\nat www.gutenberg.org. If you are not located in the United States, \\r\\nyou will have to check the laws of the country where you are located \\r\\nbefore using this eBook.\\r\\n\\r\\n\\r\\n\\r\\n    \\r\\n        Title: Shakespeare's Sonnets\\r\\n        \\r\\n        Author: William Shakespeare\\r\\n\\r\\n        \\r\\n        Release date: September 1, 1997 [eBook #1041]Most recently updated: February 27, 2023\\r\\n        Language: English\\r\\n        \\r\\n        \\r\\n    \\r\\n        \\r\\n            *** START OF THE PROJECT GUTENBERG EBOOK SHAKESPEARE'S SONNETS ***\\r\\n        \\r\\n\\r\\n\\r\\n\\r\\nTHE SONNETS\\r\\n\\r\\nby William Shakespeare\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nI\\r\\n\\r\\nFrom fairest creatures we desire increase,\\r\\nThat thereby beauty’s rose might never die,\\r\\nBut as the riper should by time decease,\\r\\nHis tender heir might bear his memory:\\r\\nBut thou, contracted to thine own bright eyes,\\r\\nFeed’st thy light’s flame with self-substantial fuel,\\r\\nMaking a famine where abundance lies,\\r\\nThyself thy foe, to thy sweet self too cruel:\\r\\nThou that art now the world’s fresh ornament,\\r\\nAnd only herald to the gaudy spring,\\r\\nWithin thine own bud buriest thy content,\\r\\nAnd tender churl mak’st waste in niggarding:\\r\\n    Pity the world, or else this glutton be,\\r\\n    To eat the world’s due, by the grave and thee.\\r\\n\\r\\nII\\r\\n\\r\\nWhen forty winters shall besiege thy brow,\\r\\nAnd dig deep trenches in thy beauty’s field,\\r\\nThy youth’s proud livery so gazed on now,\\r\\nWill be a tatter’d weed of small worth held:\\r\\nThen being asked, where all thy beauty lies,\\r\\nWhere all the treasure of thy lusty days;\\r\\nTo say, within thine own deep sunken eyes,\\r\\nWere an all-eating shame, and thriftless praise.\\r\\nHow much more praise deserv’d thy beauty’s use,\\r\\nIf thou couldst answer ‘This fair child of mine\\r\\nShall sum my count, and make my old excuse,’\\r\\nProving his beauty by succession thine!\\r\\n    This were to be new made when thou art old,\\r\\n    And see thy blood warm when thou feel’st it cold.\\r\\n\\r\\nIII\\r\\n\\r\\nLook in thy glass and tell the face thou viewest\\r\\nNow is the time that face should form another;\\r\\nWhose fresh repair if now thou not renewest,\\r\\nThou dost beguile the world, unbless some mother.\\r\\nFor where is she so fair whose unear’d womb\\r\\nDisdains the tillage of thy husbandry?\\r\\nOr who is he so fond will be the tomb,\\r\\nOf his self-love to stop posterity?\\r\\nThou art thy mother’s glass and she in thee\\r\\nCalls back the lovely April of her prime;\\r\\nSo thou through windows of thine age shalt see,\\r\\nDespite of wrinkles this thy golden time.\\r\\n    But if thou live, remember’d not to be,\\r\\n    Die single and thine image dies with thee.\\r\\n\\r\\nIV\\r\\n\\r\\nUnthrifty loveliness, why dost thou spend\\r\\nUpon thyself thy beauty’s legacy?\\r\\nNature’s bequest gives nothing, but doth lend,\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as usual, we need to clean up the messy data\n",
    "raw_text_data[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "id": "JolH-nrVcqLP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13b66e41cc64459f0757f6f53a78e08f",
     "grade": false,
     "grade_id": "cell-916f742d2cea299a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which characters could we use with the split() method to split the text into lines?\n",
    "\n",
    "# split the text into **lines** and save the result to `split_data`\n",
    "\n",
    "# YOUR CODE HERE\n",
    "split_data = raw_text_data.split('\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UuGAL77acqLQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to drop all the boiler plate text (i.e. titles and descriptions) as well as extra white spaces\n",
    "# so that we are left with only the sonnets themselves \n",
    "# split_data[:37]\n",
    "# split_data[-400:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fsYTC76cqLQ"
   },
   "source": [
    "**Use list index slicing to remove the titles and descriptions, so we only have the sonnets.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "id": "NLaFgX08cqLR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00ead0a1024ff72116c24f6b473c1aac",
     "grade": false,
     "grade_id": "cell-1f388b88b0eec24a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to drop all the boilerplate text (i.e., titles and descriptions) as well as extra white spaces\n",
    "# so that we are left with only the sonnets themselves \n",
    "\n",
    "# find index boundaries (start, end)so that \n",
    "# sonnets exist between these indices \n",
    "# titles and descriptions exist outside of these indices\n",
    "\n",
    "# use index slicing to isolate the sonnet lines from the text - save the result to `sonnets`\n",
    "\n",
    "# YOUR CODE HERE\n",
    "sonnets = split_data[37:-400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLII',\n",
       " '',\n",
       " 'In loving thee thou know’st I am forsworn,',\n",
       " 'But thou art twice forsworn, to me love swearing;',\n",
       " 'In act thy bed-vow broke, and new faith torn,',\n",
       " 'In vowing new hate after new love bearing:',\n",
       " 'But why of two oaths’ breach do I accuse thee,',\n",
       " 'When I break twenty? I am perjur’d most;',\n",
       " 'For all my vows are oaths but to misuse thee,',\n",
       " 'And all my honest faith in thee is lost:',\n",
       " 'For I have sworn deep oaths of thy deep kindness,',\n",
       " 'Oaths of thy love, thy truth, thy constancy;',\n",
       " 'And, to enlighten thee, gave eyes to blindness,',\n",
       " 'Or made them swear against the thing they see;',\n",
       " '    For I have sworn thee fair; more perjured I,',\n",
       " '    To swear against the truth so foul a lie.',\n",
       " '',\n",
       " 'CLIII',\n",
       " '',\n",
       " 'Cupid laid by his brand and fell asleep:',\n",
       " 'A maid of Dian’s this advantage found,',\n",
       " 'And his love-kindling fire did quickly steep',\n",
       " 'In a cold valley-fountain of that ground;',\n",
       " 'Which borrow’d from this holy fire of Love,',\n",
       " 'A dateless lively heat, still to endure,',\n",
       " 'And grew a seeting bath, which yet men prove',\n",
       " 'Against strange maladies a sovereign cure.',\n",
       " 'But at my mistress’ eye Love’s brand new-fired,',\n",
       " 'The boy for trial needs would touch my breast;',\n",
       " 'I, sick withal, the help of bath desired,',\n",
       " 'And thither hied, a sad distemper’d guest,',\n",
       " '    But found no cure, the bath for my help lies',\n",
       " '    Where Cupid got new fire; my mistress’ eyes.',\n",
       " '',\n",
       " 'CLIV',\n",
       " '',\n",
       " 'The little Love-god lying once asleep,',\n",
       " 'Laid by his side his heart-inflaming brand,',\n",
       " 'Whilst many nymphs that vow’d chaste life to keep',\n",
       " 'Came tripping by; but in her maiden hand',\n",
       " 'The fairest votary took up that fire',\n",
       " 'Which many legions of true hearts had warm’d;',\n",
       " 'And so the general of hot desire',\n",
       " 'Was, sleeping, by a virgin hand disarm’d.',\n",
       " 'This brand she quenched in a cool well by,',\n",
       " 'Which from Love’s fire took heat perpetual,',\n",
       " 'Growing a bath and healthful remedy,',\n",
       " 'For men diseased; but I, my mistress’ thrall,',\n",
       " '    Came there for cure and this by that I prove,',\n",
       " '    Love’s fire heats water, water cools not love.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnets[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mJReim_43Ma"
   },
   "source": [
    "Notice that there are many lines that should not be counted as sonnets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "th9BuvVlcqLR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Since sweets and beauties do themselves forsake',\n",
       " 'And die as fast as they see others grow;',\n",
       " '    And nothing ’gainst Time’s scythe can make defence',\n",
       " '    Save breed, to brave him when he takes thee hence.',\n",
       " '',\n",
       " 'XIII',\n",
       " '',\n",
       " 'O! that you were your self; but, love you are',\n",
       " 'No longer yours, than you yourself here live:',\n",
       " 'Against this coming end you should prepare,',\n",
       " 'And your sweet semblance to some other give:',\n",
       " 'So should that beauty which you hold in lease',\n",
       " 'Find no determination; then you were',\n",
       " 'Yourself again, after yourself’s decease,',\n",
       " 'When your sweet issue your sweet form should bear.',\n",
       " 'Who lets so fair a house fall to decay,',\n",
       " 'Which husbandry in honour might uphold,',\n",
       " 'Against the stormy gusts of winter’s day',\n",
       " 'And barren rage of death’s eternal cold?',\n",
       " '    O! none but unthrifts. Dear my love, you know,',\n",
       " '    You had a father: let your son say so.',\n",
       " '',\n",
       " 'XIV',\n",
       " '',\n",
       " 'Not from the stars do I my judgement pluck;',\n",
       " 'And yet methinks I have astronomy,',\n",
       " 'But not to tell of good or evil luck,',\n",
       " 'Of plagues, of dearths, or seasons’ quality;',\n",
       " 'Nor can I fortune to brief minutes tell,',\n",
       " 'Pointing to each his thunder, rain and wind,',\n",
       " 'Or say with princes if it shall go well',\n",
       " 'By oft predict that I in heaven find:',\n",
       " 'But from thine eyes my knowledge I derive,',\n",
       " 'And constant stars in them I read such art',\n",
       " 'As ‘Truth and beauty shall together thrive,',\n",
       " 'If from thyself, to store thou wouldst convert’;',\n",
       " '    Or else of thee this I prognosticate:',\n",
       " '    ‘Thy end is truth’s and beauty’s doom and date.’',\n",
       " '',\n",
       " 'XV']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these non-sonnet lines have far fewer characters than the actual sonnet lines?\n",
    "\n",
    "sonnets[200:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "id": "OiOfyPexcqLS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "649cf52260448a5faf539ad6b6e8e6e8",
     "grade": false,
     "grade_id": "cell-84c4b3cf1f3c032a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use your judgement to decide on a good value for  \n",
    "#   the  minimum number of characters that a sonnet should have\n",
    "#   call it n_chars\n",
    "n_chars = 10\n",
    "\n",
    "# Let's use that observation to filter out all the non-sonnet lines!\n",
    "#    save results to `filtered_sonnets`\n",
    "# Hint: use a list comprehension\n",
    "\n",
    "# YOUR CODE HERE\n",
    "filtered_sonnets = [line.strip() for line in sonnets if len(line) > n_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xW_AFhCUcqLS",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From fairest creatures we desire increase,',\n",
       " 'That thereby beauty’s rose might never die,',\n",
       " 'But as the riper should by time decease,',\n",
       " 'His tender heir might bear his memory:',\n",
       " 'But thou, contracted to thine own bright eyes,',\n",
       " 'Feed’st thy light’s flame with self-substantial fuel,',\n",
       " 'Making a famine where abundance lies,',\n",
       " 'Thyself thy foe, to thy sweet self too cruel:',\n",
       " 'Thou that art now the world’s fresh ornament,',\n",
       " 'And only herald to the gaudy spring,',\n",
       " 'Within thine own bud buriest thy content,',\n",
       " 'And tender churl mak’st waste in niggarding:',\n",
       " 'Pity the world, or else this glutton be,',\n",
       " 'To eat the world’s due, by the grave and thee.',\n",
       " 'When forty winters shall besiege thy brow,',\n",
       " 'And dig deep trenches in thy beauty’s field,',\n",
       " 'Thy youth’s proud livery so gazed on now,',\n",
       " 'Will be a tatter’d weed of small worth held:',\n",
       " 'Then being asked, where all thy beauty lies,',\n",
       " 'Where all the treasure of thy lusty days;',\n",
       " 'To say, within thine own deep sunken eyes,',\n",
       " 'Were an all-eating shame, and thriftless praise.',\n",
       " 'How much more praise deserv’d thy beauty’s use,',\n",
       " 'If thou couldst answer ‘This fair child of mine',\n",
       " 'Shall sum my count, and make my old excuse,’',\n",
       " 'Proving his beauty by succession thine!',\n",
       " 'This were to be new made when thou art old,',\n",
       " 'And see thy blood warm when thou feel’st it cold.',\n",
       " 'Look in thy glass and tell the face thou viewest',\n",
       " 'Now is the time that face should form another;',\n",
       " 'Whose fresh repair if now thou not renewest,',\n",
       " 'Thou dost beguile the world, unbless some mother.',\n",
       " 'For where is she so fair whose unear’d womb',\n",
       " 'Disdains the tillage of thy husbandry?',\n",
       " 'Or who is he so fond will be the tomb,',\n",
       " 'Of his self-love to stop posterity?',\n",
       " 'Thou art thy mother’s glass and she in thee',\n",
       " 'Calls back the lovely April of her prime;',\n",
       " 'So thou through windows of thine age shalt see,',\n",
       " 'Despite of wrinkles this thy golden time.',\n",
       " 'But if thou live, remember’d not to be,',\n",
       " 'Die single and thine image dies with thee.',\n",
       " 'Unthrifty loveliness, why dost thou spend',\n",
       " 'Upon thyself thy beauty’s legacy?',\n",
       " 'Nature’s bequest gives nothing, but doth lend,',\n",
       " 'And being frank she lends to those are free:',\n",
       " 'Then, beauteous niggard, why dost thou abuse',\n",
       " 'The bounteous largess given thee to give?',\n",
       " 'Profitless usurer, why dost thou use',\n",
       " 'So great a sum of sums, yet canst not live?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok - much better!\n",
    "# but we still need to remove all the punctuation and case normalize the text\n",
    "filtered_sonnets[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iD4oqhVcqLT"
   },
   "source": [
    "### Use Custom Data Cleaning Tool \n",
    "\n",
    "Use one of the methods in the `data_cleaning_toolkit` to clean your data.\n",
    "\n",
    "There is an example of this in the guided project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "id": "S7V1Q0h_cqLT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a722083a29139936744ff9a341e1c9a3",
     "grade": false,
     "grade_id": "cell-775c14b456d8a724",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate the data_cleaning_toolkit class - save result to `dctk`\n",
    "\n",
    "# YOUR CODE HERE\n",
    "dctk = data_cleaning_toolkit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "id": "YquHh21GcqLT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab91e612cd08068f3a36172979157d5d",
     "grade": false,
     "grade_id": "cell-684010b6a7360876",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use data_cleaning_toolkit to remove punctuation and to case normalize - save results to `clean_sonnets`\n",
    "\n",
    "# YOUR CODE HERE\n",
    "clean_sonnets = [dctk.clean_data(line) for line in filtered_sonnets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dN3vWjofcqLT",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from fairest creatures we desire increase',\n",
       " 'that thereby beautys rose might never die',\n",
       " 'but as the riper should by time decease',\n",
       " 'his tender heir might bear his memory',\n",
       " 'but thou contracted to thine own bright eyes',\n",
       " 'feedst thy lights flame with selfsubstantial fuel',\n",
       " 'making a famine where abundance lies',\n",
       " 'thyself thy foe to thy sweet self too cruel',\n",
       " 'thou that art now the worlds fresh ornament',\n",
       " 'and only herald to the gaudy spring',\n",
       " 'within thine own bud buriest thy content',\n",
       " 'and tender churl makst waste in niggarding',\n",
       " 'pity the world or else this glutton be',\n",
       " 'to eat the worlds due by the grave and thee',\n",
       " 'when forty winters shall besiege thy brow',\n",
       " 'and dig deep trenches in thy beautys field',\n",
       " 'thy youths proud livery so gazed on now',\n",
       " 'will be a tatterd weed of small worth held',\n",
       " 'then being asked where all thy beauty lies',\n",
       " 'where all the treasure of thy lusty days',\n",
       " 'to say within thine own deep sunken eyes',\n",
       " 'were an alleating shame and thriftless praise',\n",
       " 'how much more praise deservd thy beautys use',\n",
       " 'if thou couldst answer this fair child of mine',\n",
       " 'shall sum my count and make my old excuse',\n",
       " 'proving his beauty by succession thine',\n",
       " 'this were to be new made when thou art old',\n",
       " 'and see thy blood warm when thou feelst it cold',\n",
       " 'look in thy glass and tell the face thou viewest',\n",
       " 'now is the time that face should form another',\n",
       " 'whose fresh repair if now thou not renewest',\n",
       " 'thou dost beguile the world unbless some mother',\n",
       " 'for where is she so fair whose uneard womb',\n",
       " 'disdains the tillage of thy husbandry',\n",
       " 'or who is he so fond will be the tomb',\n",
       " 'of his selflove to stop posterity',\n",
       " 'thou art thy mothers glass and she in thee',\n",
       " 'calls back the lovely april of her prime',\n",
       " 'so thou through windows of thine age shalt see',\n",
       " 'despite of wrinkles this thy golden time',\n",
       " 'but if thou live rememberd not to be',\n",
       " 'die single and thine image dies with thee',\n",
       " 'unthrifty loveliness why dost thou spend',\n",
       " 'upon thyself thy beautys legacy',\n",
       " 'natures bequest gives nothing but doth lend',\n",
       " 'and being frank she lends to those are free',\n",
       " 'then beauteous niggard why dost thou abuse',\n",
       " 'the bounteous largess given thee to give',\n",
       " 'profitless usurer why dost thou use',\n",
       " 'so great a sum of sums yet canst not live']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155\n"
     ]
    }
   ],
   "source": [
    "# much better!\n",
    "display(clean_sonnets[:50])\n",
    "print(len(clean_sonnets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSfirtmYcqLT"
   },
   "source": [
    "### Use Your Data Tool to Create Character Sequences \n",
    "for the LSTM model\n",
    "\n",
    "We'll need the `create_char_sequences` method for this task. <br>\n",
    "However, this method requires a parameter called `maxlen,` which is responsible for setting the maximum sequence length. \n",
    "\n",
    "So what would be a good sequence length, exactly? \n",
    "\n",
    "To answer that question, let's do some statistics! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "id": "O7Buzpw3cqLU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1deebea2ada0a7dc7d2eb08295ee1e2b",
     "grade": false,
     "grade_id": "cell-9ebdaa2654dd29ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_stats(corpus):\n",
    "    \"\"\"\n",
    "    Calculates statistics on the length of every line in the sonnets\n",
    "    \"\"\"\n",
    "    \n",
    "    # write a list comprehension that calculates each sonnet's line length - save the results to `doc_lens` \n",
    "\n",
    "    # use numpy to calculate and return the mean, median, std, max, min of the doc lens - all in one line of code\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    doc_lens = [len(line) for line in corpus]\n",
    "    return np.mean(doc_lens), np.median(doc_lens), np.std(doc_lens), np.max(doc_lens), np.min(doc_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6DGCJO_QcqLU",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40.88027842227378, 41.0, 4.043677533721869, 57, 27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sonnet line length statistics \n",
    "mean, med, std, max_, min_ = calc_stats(clean_sonnets)\n",
    "mean, med, std, max_, min_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "WOCylsbLcqLU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "690957e46b6f2f32c1f17756d8ceab5b",
     "grade": false,
     "grade_id": "cell-35185e26897aad7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 18047 sequences.\n"
     ]
    }
   ],
   "source": [
    "# from the results of the sonnet line length statistics, use your judgement to select a value for maxlen\n",
    "#   hint -- a good value might be half the median length of a sonnet line\n",
    "# use .create_char_sequences() to create sequences\n",
    "\n",
    "# YOUR CODE HERE\n",
    "maxlen = 20\n",
    "dctk.create_char_sequences(clean_sonnets, maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hutUpE9cqLV"
   },
   "source": [
    "Take a look at the `data_cleaning_toolkit_class.py` file. \n",
    "\n",
    "In the first 4 lines of code in the `create_char_sequences` method, class attributes `n_features` and `unique_chars` are created. <br>\n",
    "Let's call them in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "C8BNLJuhcqLV",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# number of input features for our LSTM model\n",
    "print(dctk.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uQrPRQy3cqLV",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'e',\n",
       " 't',\n",
       " 'r',\n",
       " 'd',\n",
       " 'y',\n",
       " 'o',\n",
       " 'x',\n",
       " 'k',\n",
       " 'p',\n",
       " 'v',\n",
       " 'b',\n",
       " 'm',\n",
       " 'w',\n",
       " 'n',\n",
       " 'j',\n",
       " 'f',\n",
       " 'c',\n",
       " 'a',\n",
       " 'u',\n",
       " 'i',\n",
       " 'g',\n",
       " 'z',\n",
       " 'q',\n",
       " 'h',\n",
       " 'l',\n",
       " 's']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique characters that appear in our sonnets \n",
    "dctk.unique_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5EaCiiBcqLV"
   },
   "source": [
    "## Time for Questions \n",
    "\n",
    "----\n",
    "**Question 1:** \n",
    "\n",
    "Why are the `number of unique characters` (i.e., **dctk.unique_chars**) and the `number of model input features` (i.e., **dctk.n_features**) the same?\n",
    "\n",
    "**Hint:** The model that we will shortly build here is very similar to the text generation model we built in the guided project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-ke3hsFcqLV"
   },
   "source": [
    "**Answer 1:**\n",
    "\n",
    "Our model is receiving input one character at a time, therefore we are essentially creating a classifier where the classes are english characters (letters and spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPiNJ6FmcqLW"
   },
   "source": [
    "\n",
    "**Question 2:**\n",
    "\n",
    "Take a look at the printout of `dctk.unique_chars` one more time. Notice that there is a white space. \n",
    "\n",
    "Why is it desirable to have a white space as a possible character to predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1yVqEWZcqLW"
   },
   "source": [
    "**Answer 2:**\n",
    "\n",
    "We want our model to output words, but we're technically outputing one character at a time, therefore we need to be able to output spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAwB6dLHcqLW"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXZMkLckcqLW"
   },
   "source": [
    "### Use Our Data Tool to Create X and Y Splits\n",
    "\n",
    "You'll need the `create_X_and_Y` method for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JK-1GQzncqLW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: provide a walkthrough of data_cleaning_toolkit with unit tests that check for understanding \n",
    "X, y = dctk.create_X_and_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gvcygSTcqLW"
   },
   "source": [
    "![](https://miro.medium.com/max/891/0*jGB1CGQ9HdeUwlgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6xtDCd8wcqLW",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18047, 20, 27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice that our input array isn't a matrix - it's a rank three tensor\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0_YHHQdcqLX"
   },
   "source": [
    "In $X$.shape, we see three numbers (*n1*, *n2*, *n3*). What do these numbers mean?\n",
    "\n",
    "Well, *n1* tells us the number of samples that we have. But what about the other two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "jB-n6_P4cqLX",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True],\n",
       "       [False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False,  True, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True],\n",
       "       [False, False, False, False, False, False, False,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first index returns a signle sample, which we can see is a sequence \n",
    "first_sample_index = 0 \n",
    "X[first_sample_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A75Caji7cqLX"
   },
   "source": [
    "Notice that each sequence (i.e., $X[i]$ where $i$ is some index value) is `maxlen` long and <br>\n",
    "has a number of features equal to `dctk.n_features`. <br>Let's try to understand this shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Q1E8AFAIcqLX",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 27)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each sequence is maxlen long and has dctk.n_features number of features\n",
    "X[first_sample_index].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iChccLKWcqLX"
   },
   "source": [
    "**Each row corresponds to a character vector,** and there is `maxlen` number of character vectors. \n",
    "\n",
    "**Each column corresponds to a unique character,** and there are `dctk.n_features` number of features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "IbWKVpd5cqLX",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's index for a single character vector \n",
    "first_char_vect_index = 0\n",
    "X[first_sample_index][first_char_vect_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cVGE3wtcqLX"
   },
   "source": [
    "Notice that there is a single `True` value, and all the rest of the values are `False`. \n",
    "\n",
    "This is a one-hot encoding for which character appears at each index within a sequence. Specifically, the cell above is looking at the first character in the sequence.\n",
    "\n",
    "Only a single character can appear as the first character in a sequence, so there will be a single `True` value, and the rest will be `False`. \n",
    "\n",
    "Let's say that `True` appears in the $ith$ index; by  $ith$ index we mean some index in the general case. So how can we find out which character corresponds to?\n",
    "\n",
    "To answer this question, we need to use the character-to-integer look-up dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "RJ8dIATxcqLX",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'y',\n",
       " 1: 'd',\n",
       " 2: 'z',\n",
       " 3: 'j',\n",
       " 4: 'k',\n",
       " 5: 'l',\n",
       " 6: 'r',\n",
       " 7: 'a',\n",
       " 8: 'n',\n",
       " 9: 'e',\n",
       " 10: 'w',\n",
       " 11: 'b',\n",
       " 12: 'c',\n",
       " 13: ' ',\n",
       " 14: 'o',\n",
       " 15: 'x',\n",
       " 16: 's',\n",
       " 17: 't',\n",
       " 18: 'v',\n",
       " 19: 'i',\n",
       " 20: 'u',\n",
       " 21: 'h',\n",
       " 22: 'q',\n",
       " 23: 'm',\n",
       " 24: 'g',\n",
       " 25: 'p',\n",
       " 26: 'f'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the index to character dictionary\n",
    "# if a TRUE appears in the 0th index of a character vector,\n",
    "# then we know that whatever char you see below next to the 0th key \n",
    "# is the character that character vector is endcoding for\n",
    "dctk.int_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lXy52FuHcqLY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "Sequence length: 20\n"
     ]
    }
   ],
   "source": [
    "# let's look at an example to tie it all together\n",
    "\n",
    "seq_len_counter = 0\n",
    "\n",
    "# index for a single sample \n",
    "for seq_of_char_vects in X[first_sample_index]:\n",
    "    \n",
    "    # get index with max value, which will be the one TRUE value \n",
    "    index_with_TRUE_val = np.argmax(seq_of_char_vects)\n",
    "    \n",
    "    print (dctk.int_char[index_with_TRUE_val])\n",
    "    \n",
    "    seq_len_counter+=1\n",
    "    \n",
    "print (\"Sequence length: {}\".format(seq_len_counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufESNp0mcqLY"
   },
   "source": [
    "## Time for Questions \n",
    "\n",
    "----\n",
    "**Question 1:** \n",
    "\n",
    "In your own words, how would you describe the numbers from the shape printout of `X.shape` to a classmate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfuBw3hHcqLY"
   },
   "source": [
    "**Answer 1:**\n",
    "\n",
    "(a, b, c) corresponds to (number of char sequences, chars in a sequence, one-hot encoding of a char into our features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-H9jSq6cqLY"
   },
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7Fo7tn5cqLY"
   },
   "source": [
    "### Build a Shakespeare Sonnet Text Generation Model\n",
    "\n",
    "Now that we have prepped our data (and understood that process), let's finally build out our character generation model, similar to what we did in the guided project.<br>\n",
    "\n",
    "First, we'll create a callback to monitor the training -- by printing a sample of text generated by the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVc4tb1OSMMr"
   },
   "source": [
    "Helper function to generate a sample character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "9Xgk-JomzwGX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Helper function to generate a sample character\n",
    "    Input is a predictions vector from our model, for example a set of 27 character probabilities\n",
    "    Output is the index of the generated character \n",
    "    \"\"\"\n",
    "    # convert predictions to an array \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "    # use the temperature hyper-parameter to \"warp\" (sharpen or spread out) the probability distribution \n",
    "    preds = np.log(preds) / temperature\n",
    "\n",
    "    # use the softmax activation function to create a new list of probabilities \n",
    "    #   corresponding to the \"warped\" probability distribution\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    # Draw a single sample from a multinomial distribution, given these probabilities\n",
    "    #   The sample will be a one-hot encoded character\n",
    "    \"\"\" Notes on the np.random.multinomial() function \n",
    "       The first argument is the number of \"trials\" we want: 1 in this case\n",
    "       The second argument is the list of probabilities for each character\n",
    "       The third argument is number of sets of \"trials\" we want: again, 1 in this case\n",
    "       By analogy with a dice-rolling experiment: \n",
    "          This \"trial\" consists of generating a single \"throw\" of a die with 27 faces;\n",
    "             each face corresponds to a character and its associated probability\n",
    "    \"\"\"\n",
    "\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    # return the index that corresponds to the max probability \n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPhu860ZEd3g"
   },
   "source": [
    "Create the `on_epoch_end` function to be passed into `LambdaCallback()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "o9cBsweJcqLY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"\"\n",
    "    Function invoked at the end of each epoch. Prints the text generated by our model.\n",
    "    \"\"\"\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "\n",
    "    # randomly pick a starting index \n",
    "    # will be used to take a random sequence of chars from `text`\n",
    "    start_index = random.randint(0, len(text) - dctk.maxlen - 1)\n",
    "    \n",
    "    # this is our seed string (i.e. input seqeunece into the model)\n",
    "    generated = ''\n",
    "\n",
    "    # start the sentence at index `start_index` and include the next` dctk.maxlen` number of chars\n",
    "    sentence = text[start_index: start_index + dctk.maxlen]\n",
    "\n",
    "    # add to generated\n",
    "    generated += sentence\n",
    "\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    # use model to predict what the next maxlen chars should be that follow the seed string\n",
    "    for i in range(maxlen):\n",
    "\n",
    "        # shape of a single sample in a rank 3 tensor \n",
    "        x_dims = (1, dctk.maxlen, dctk.n_features)\n",
    "        # create an array of zeros with shape x_dims\n",
    "        # recall that python considers zeros and boolean FALSE as the same\n",
    "        x_pred = np.zeros(x_dims)\n",
    "\n",
    "        # create a seq vector for our randomly select sequence \n",
    "        # i.e. create a numerical encoding for each char in the sequence \n",
    "        for t, char in enumerate(sentence):\n",
    "            # for sample 0 in seq index t and character `char` encode a 1 (which is the same as a TRUE)\n",
    "            x_pred[0, t, dctk.char_int[char]] = 1\n",
    "\n",
    "        # next, take the seq vector and pass into model to get a prediction of what the next char should be \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        # use the sample helper function to get index for next char \n",
    "        next_index = sample(preds)\n",
    "        # use look up dict to get next char \n",
    "        next_char = dctk.int_char[next_index]\n",
    "\n",
    "        # append next char to sequence \n",
    "        sentence = sentence[1:] + next_char \n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "s6xJijWAcqLZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All of Shakespeare's sonnets comprise about 90251 characters\n"
     ]
    }
   ],
   "source": [
    "# need this for on_epoch_end()\n",
    "text = \" \".join(clean_sonnets)\n",
    "print(f'All of Shakespeare\\'s sonnets comprise about {len(text)} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91FywCwoUzn0"
   },
   "source": [
    "Create the callback object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "TKDdNLhBcqLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create callback object that will print out text generation at the end of each epoch \n",
    "# use for real-time monitoring of model performance\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Cq75YmTcqLZ"
   },
   "source": [
    "----\n",
    "### Build and Train Model\n",
    "\n",
    "Build a text generation model using LSTMs. Feel free to reference the model used in the guided project. \n",
    "\n",
    "It is recommended that you train this model to at least 50 epochs (but more if you're computer can handle it). \n",
    "\n",
    "You are free to change up the architecture as you wish. \n",
    "\n",
    "Just in case you have difficultly training a model, there is a pre-trained model saved to a file called `trained_text_gen_model.h5` that you can load (in the same way that you learned how to load in Keras models in Sprint 2 Module 4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "id": "3JLmhL36cqLZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e17312b57e17284124ce562dff81b00d",
     "grade": false,
     "grade_id": "cell-f34be90367fd9071",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.9106\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"en pilgrimage but wh\"\n",
      "en pilgrimage but wh hc othnefwc   batr \n",
      "71/71 [==============================] - 9s 122ms/step - loss: 2.9106\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.8308\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"not marble nor the g\"\n",
      "not marble nor the g yo s ebrrhshkfht he\n",
      "71/71 [==============================] - 9s 128ms/step - loss: 2.8308\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.8034\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"a makeless wife the \"\n",
      "a makeless wife the a al cdote dtbhttreb\n",
      "71/71 [==============================] - 9s 131ms/step - loss: 2.8034\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.6354\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"mers time the teemin\"\n",
      "mers time the teemintte oliso ooat gorf \n",
      "71/71 [==============================] - 10s 139ms/step - loss: 2.6354\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.4189\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \" you pattern of all \"\n",
      " you pattern of all thimdes hocs bef th \n",
      "71/71 [==============================] - 9s 128ms/step - loss: 2.4189\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.2799\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"o bright as those go\"\n",
      "o bright as those got dceemign if oror o\n",
      "71/71 [==============================] - 9s 127ms/step - loss: 2.2799\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.2058\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"the very refuse of t\"\n",
      "the very refuse of torne the in do int p\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 2.2058\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.1527\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"lowers in odour and \"\n",
      "lowers in odour and ank in anke shorge s\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 2.1527\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.1030\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \" and brought to medi\"\n",
      " and brought to medincang srang cint ou \n",
      "71/71 [==============================] - 9s 133ms/step - loss: 2.1030\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.0537\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"that plea deny and s\"\n",
      "that plea deny and sop not aspier my wee\n",
      "71/71 [==============================] - 9s 126ms/step - loss: 2.0537\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.0228\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"tion chose out thee \"\n",
      "tion chose out thee didw move wres liven\n",
      "71/71 [==============================] - 10s 140ms/step - loss: 2.0228\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.9805\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"done mine eyes have \"\n",
      "done mine eyes have lovy frawer hart sei\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 1.9805\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.9488\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \" am debarred the ben\"\n",
      " am debarred the benow hat thand eiou ma\n",
      "71/71 [==============================] - 9s 122ms/step - loss: 1.9488\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.9213\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \" by day or gluttonin\"\n",
      " by day or gluttoning commsde dxming bot\n",
      "71/71 [==============================] - 10s 134ms/step - loss: 1.9213\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.8804\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"t he that writes of \"\n",
      "t he that writes of than pace gome thanc\n",
      "71/71 [==============================] - 9s 130ms/step - loss: 1.8804\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.8525\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"f alone and to be su\"\n",
      "f alone and to be sumo yee doty treeefye\n",
      "71/71 [==============================] - 9s 127ms/step - loss: 1.8525\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.8288\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \"ou sendst from thee \"\n",
      "ou sendst from thee by swilp and poreast\n",
      "71/71 [==============================] - 9s 128ms/step - loss: 1.8288\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.8016\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"y love to thee i so \"\n",
      "y love to thee i so in subcerfers bet an\n",
      "71/71 [==============================] - 10s 134ms/step - loss: 1.8016\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.7650\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"elied with false com\"\n",
      "elied with false comerthy okntst shaless\n",
      "71/71 [==============================] - 8s 118ms/step - loss: 1.7650\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.7434\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \" thus far for love m\"\n",
      " thus far for love my derast that showes\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 1.7434\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.7105\n",
      "----- Generating text after Epoch: 20\n",
      "----- Generating with seed: \"worst of wrongs when\"\n",
      "worst of wrongs whene thoughts in of sha\n",
      "71/71 [==============================] - 10s 134ms/step - loss: 1.7105\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.6780\n",
      "----- Generating text after Epoch: 21\n",
      "----- Generating with seed: \"s which i by lacking\"\n",
      "s which i by lacking in evenyst so of wh\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 1.6780\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.6492\n",
      "----- Generating text after Epoch: 22\n",
      "----- Generating with seed: \"ats in the brain tha\"\n",
      "ats in the brain that his a and ofe pril\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 1.6492\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.6250\n",
      "----- Generating text after Epoch: 23\n",
      "----- Generating with seed: \" truth and nothing s\"\n",
      " truth and nothing stealce ill thy sacou\n",
      "71/71 [==============================] - 9s 120ms/step - loss: 1.6250\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.5882\n",
      "----- Generating text after Epoch: 24\n",
      "----- Generating with seed: \"ll shows kill me wit\"\n",
      "ll shows kill me withs a uiny and of fre\n",
      "71/71 [==============================] - 9s 129ms/step - loss: 1.5882\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.5607\n",
      "----- Generating text after Epoch: 25\n",
      "----- Generating with seed: \"ke old men of less t\"\n",
      "ke old men of less the eet wuintoupeding\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 1.5607\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.5317\n",
      "----- Generating text after Epoch: 26\n",
      "----- Generating with seed: \" pace therefore desi\"\n",
      " pace therefore desimths be fain thy hea\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 1.5317\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.5010\n",
      "----- Generating text after Epoch: 27\n",
      "----- Generating with seed: \"m she best endowd sh\"\n",
      "m she best endowd should suw all toupuld\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 1.5010\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.4733\n",
      "----- Generating text after Epoch: 28\n",
      "----- Generating with seed: \" even to thy pure an\"\n",
      " even to thy pure and niden des for me e\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 1.4733\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.4296\n",
      "----- Generating text after Epoch: 29\n",
      "----- Generating with seed: \"t those tears are pe\"\n",
      "t those tears are pend nor that life my \n",
      "71/71 [==============================] - 9s 126ms/step - loss: 1.4296\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.3776\n",
      "----- Generating text after Epoch: 30\n",
      "----- Generating with seed: \"ind the lesson true \"\n",
      "ind the lesson true ais it my leaving ga\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 1.3776\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.3518\n",
      "----- Generating text after Epoch: 31\n",
      "----- Generating with seed: \"unt invention quite \"\n",
      "unt invention quite bus thy love tuth al\n",
      "71/71 [==============================] - 9s 131ms/step - loss: 1.3518\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.3022\n",
      "----- Generating text after Epoch: 32\n",
      "----- Generating with seed: \"yourself in eyes of \"\n",
      "yourself in eyes of that betw stane she \n",
      "71/71 [==============================] - 9s 130ms/step - loss: 1.3022\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.2481\n",
      "----- Generating text after Epoch: 33\n",
      "----- Generating with seed: \"l perfumes in three \"\n",
      "l perfumes in three and benteward ow wer\n",
      "71/71 [==============================] - 9s 131ms/step - loss: 1.2481\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.2150\n",
      "----- Generating text after Epoch: 34\n",
      "----- Generating with seed: \"s by night my mind f\"\n",
      "s by night my mind fomind of nad wramses\n",
      "71/71 [==============================] - 9s 128ms/step - loss: 1.2150\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.1707\n",
      "----- Generating text after Epoch: 35\n",
      "----- Generating with seed: \"y registers and thee\"\n",
      "y registers and thee this of thy live ey\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 1.1707\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.1133\n",
      "----- Generating text after Epoch: 36\n",
      "----- Generating with seed: \"ons of eisel gainst \"\n",
      "ons of eisel gainst ofient sriet pricit \n",
      "71/71 [==============================] - 10s 141ms/step - loss: 1.1133\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.0837\n",
      "----- Generating text after Epoch: 37\n",
      "----- Generating with seed: \" rare since seldom c\"\n",
      " rare since seldom call touke fise mishi\n",
      "71/71 [==============================] - 9s 126ms/step - loss: 1.0837\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.0214\n",
      "----- Generating text after Epoch: 38\n",
      "----- Generating with seed: \"ght think me some un\"\n",
      "ght think me some undel of thy see the l\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 1.0214\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.9760\n",
      "----- Generating text after Epoch: 39\n",
      "----- Generating with seed: \"ection should he liv\"\n",
      "ection should he live a preser sucllasi \n",
      "71/71 [==============================] - 10s 147ms/step - loss: 0.9760\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.9301\n",
      "----- Generating text after Epoch: 40\n",
      "----- Generating with seed: \"t from my loves brea\"\n",
      "t from my loves brear thencion mine ase \n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.9301\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8761\n",
      "----- Generating text after Epoch: 41\n",
      "----- Generating with seed: \"ower o how shall sum\"\n",
      "ower o how shall summers lest thou meys \n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.8761\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8146\n",
      "----- Generating text after Epoch: 42\n",
      "----- Generating with seed: \"is as a fever longin\"\n",
      "is as a fever longing brong thy stare th\n",
      "71/71 [==============================] - 9s 120ms/step - loss: 0.8146\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7913\n",
      "----- Generating text after Epoch: 43\n",
      "----- Generating with seed: \"me alone but slave t\"\n",
      "me alone but slave thou dright owal hear\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 0.7913\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7272\n",
      "----- Generating text after Epoch: 44\n",
      "----- Generating with seed: \"ay time disgrace and\"\n",
      "ay time disgrace and truent king and but\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 0.7272\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6801\n",
      "----- Generating text after Epoch: 45\n",
      "----- Generating with seed: \"ith weary car like f\"\n",
      "ith weary car like for beautyst freez i \n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.6801\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6441\n",
      "----- Generating text after Epoch: 46\n",
      "----- Generating with seed: \"to the weary night d\"\n",
      "to the weary night draud my love furm is\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.6441\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6082\n",
      "----- Generating text after Epoch: 47\n",
      "----- Generating with seed: \"inful earth these re\"\n",
      "inful earth these relelists i can me mor\n",
      "71/71 [==============================] - 9s 130ms/step - loss: 0.6082\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5480\n",
      "----- Generating text after Epoch: 48\n",
      "----- Generating with seed: \"ll such and ever so \"\n",
      "ll such and ever so keling and tenpincul\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.5480\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.5216\n",
      "----- Generating text after Epoch: 49\n",
      "----- Generating with seed: \"am doth flatter in s\"\n",
      "am doth flatter in speeces asting tone a\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.5216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280af3dd0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build text generation model layer by layer \n",
    "# fit model\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = Sequential([\n",
    "    LSTM(264, input_shape=(dctk.maxlen, dctk.n_features), return_sequences=True, activation='relu'),\n",
    "    LSTM(128, activation='relu'),\n",
    "    Dense(dctk.n_features, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(X, y, batch_size=256, epochs=50, callbacks=[print_callback], workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94I0bGvfJQ0a"
   },
   "source": [
    "### Save the trained model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "4amWje1ncqLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save trained model to file \n",
    "model.save(\"trained_text_gen_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWWRV1VJcqLa"
   },
   "source": [
    "### Let's Play With Our Trained Model \n",
    "\n",
    "Now that we have a trained model that, though far from perfect, can generate actual English words, we can look at the predictions to continue learning more about how a text generation model works.\n",
    "\n",
    "We can also take this as an opportunity to unpack the `def on_epoch_end` function to understand better how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "gktQ5JQqcqLa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from fairest creatures we desire increase that thereby beautys rose might never die but as the riper'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our joined clean sonnet data\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "kSGHFS4QcqLa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30895"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly pick a starting index \n",
    "# will be used to take a random sequence of chars from `text`\n",
    "# run this cell a few times and you'll see `start_index` is random\n",
    "start_index = random.randint(0, len(text) - dctk.maxlen - 1)\n",
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "2ak7epOKcqLa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next use the randomly selected starting index to sample a sequence from the `text`\n",
    "\n",
    "# this is our seed string (i.e., input sequence into the model)\n",
    "generated = ''\n",
    "\n",
    "# start the sentence at index `start_index` and include the next` dctk.maxlen` number of chars\n",
    "sentence = text[start_index: start_index + dctk.maxlen]\n",
    "\n",
    "# add to generated\n",
    "generated += sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "QfbUcUBXcqLa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input seed: \"end since every one \"\n"
     ]
    }
   ],
   "source": [
    "# display the \"seed string\" i.e. the input sequence into the model\n",
    "print('----- Input seed: \"' + sentence + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "6nop-G7CcqLa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use model to predict what the next maxlen chars should be that follow the seed string\n",
    "for i in range(maxlen):\n",
    "\n",
    "    # shape of a single sample in a rank 3 tensor \n",
    "    x_dims = (1, dctk.maxlen, dctk.n_features)\n",
    "    # create an array of zeros with shape x_dims\n",
    "    # recall that python considers zeros and boolean FALSE as the same\n",
    "    x_pred = np.zeros(x_dims)\n",
    "\n",
    "    # create a seq vector for our randomly select sequence \n",
    "    # i.e. create a numerical encoding for each char in the sequence \n",
    "    for t, char in enumerate(sentence):\n",
    "        # for sample 0 in seq index t and character `char` encode a 1 (which is the same as a TRUE)\n",
    "        x_pred[0, t, dctk.char_int[char]] = 1\n",
    "\n",
    "    # next, take the seq vector and pass into model to get a prediction of what the next char should be \n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    # use the sample helper function to get index for next char \n",
    "    next_index = sample(preds)\n",
    "    # use look up dict to get next char \n",
    "    next_char = dctk.int_char[next_index]\n",
    "\n",
    "    # append next char to sequence \n",
    "    sentence = sentence[1:] + next_char "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "wX9daz2rcqLb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end since every one '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the seed string\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "a3jnYVwccqLb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hath heart herar i c'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the maxlen chars that the model thinks should come after the seed stirng\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "O1aqFH4BcqLb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end since every one hath heart herar i c'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how put it all together\n",
    "generated + sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch Goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g., plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://www.tensorflow.org/text/tutorials/text_generation) - code for training an RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem and provides an example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyGlTC_8Z4Ea"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_431_RNN_and_LSTM_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nteract": {
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
