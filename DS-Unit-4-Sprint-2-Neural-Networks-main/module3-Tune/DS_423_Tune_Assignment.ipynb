{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "\n",
    "\n",
    "# Hyperparameter Tuning Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "# Gridsearch Hyperparameters\n",
    "\n",
    "In the guided project, you learned how to use sklearn's `GridsearchCV` and `keras-tuner` libraries to tune the hyperparameters of a neural network model. For your module project you'll continue using these two libraries, however we are going to make things a little more interesting for you. \n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. \n",
    "\n",
    "\n",
    "\n",
    "**Don't forget to switch to GPU on Colab!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7oEgGCV3_hY"
   },
   "source": [
    "## 0.1 Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5855,
     "status": "ok",
     "timestamp": 1639004211787,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "DxctNMPb7mNY",
    "outputId": "7ae83304-2e15-4095-c3e2-dec49018a424",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/9b73nm7x0d5bz481kpj_k3640000gn/T/ipykernel_7347/2835263299.py:24: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch, BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "# native python libraries imports \n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn imports \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# keras imports \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "# required for compatibility between sklearn and keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# install keras-tuner\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMBS8CRBzYqB"
   },
   "source": [
    "## 0.2 Load quickdraw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kr8w6IX37mNa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_quickdraw10():\n",
    "    \"\"\"\n",
    "    Fill out this doc string, and comment the code, for practice in writing the kind of code that will get you hired. \n",
    "    \"\"\"\n",
    "    \n",
    "#     URL_ = \"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\n",
    "    \n",
    "#     path_to_zip = get_file('./quickdraw10.npz', origin=URL_, extract=False)\n",
    "\n",
    "    data = np.load('../quickdraw10.npz')\n",
    "    \n",
    "    # normalize your image data\n",
    "    max_pixel_value = 255\n",
    "    X = data['arr_0']/max_pixel_value\n",
    "    Y = data['arr_1']\n",
    "        \n",
    "    return train_test_split(X, Y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2295,
     "status": "ok",
     "timestamp": 1631203627574,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "UjU5nY3e7mNc",
    "outputId": "1c297e7d-8b3e-4284-cc83-c9ecbffe588f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_quickdraw10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qkvBPoUy7mNd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e4dx6VA07mNe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXsWtj8Z7mNf"
   },
   "source": [
    "_____\n",
    "\n",
    "# Experiment 1\n",
    "\n",
    "## Tune Hyperperameters using Enhanced GridsearchCV \n",
    "\n",
    "We are going to use GridsearchCV again to tune a deep learning model however we are going to add some additional functionality to our gridsearch. \n",
    "\n",
    "Specifically, we are going to automate the generation of how many nodes to use in a layer and how many layers to use in a model! \n",
    "\n",
    "By the way, yes, there is a function within a function. Try to not let that bother you. An alternative to this would be to create a class. If you're up for the challenge give it a shot. However, consider this a stretch goal that you come back to after you finish going through this assignment. \n",
    "\n",
    "\n",
    "### Objective \n",
    "\n",
    "The objective of this experiment is to show you how to automate the generation of layers and layer nodes for the purposes of gridsearch. <br>\n",
    "Up until now, we've been manually selecting the number of layers and layer nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "USXjs7Hk71Hy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
    "    \"\"\"\"\n",
    "    Returns a compiled keras model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_layers: int \n",
    "        number of hidden layers in model \n",
    "        To be clear, this excludes the input and output layer.\n",
    "        \n",
    "    first_layer_nodes: int\n",
    "        Number of nodes in the first hidden layer \n",
    "\n",
    "    last_layer_nodes: int\n",
    "        Number of nodes in the last hidden layer (this is the layer just prior to the output layer)\n",
    "        \n",
    "     act_funct: string \n",
    "         Name of activation function to use in hidden layers (this excludes the output layer)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model: keras object \n",
    "    \"\"\"\n",
    "    \n",
    "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
    "        \"\"\"\n",
    "        Generates and returns the number of nodes in each hidden layer. \n",
    "        To be clear, this excludes the input and output layer. \n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        Number of nodes in each layer is linearly incremented. \n",
    "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_layers: int\n",
    "            Number of hidden layers\n",
    "            This values should be 2 or greater \n",
    "\n",
    "        first_layer_nodes: int\n",
    "\n",
    "        last_layer_nodes: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        layers: list of ints\n",
    "            Contains number of nodes for each layer \n",
    "        \"\"\"\n",
    "\n",
    "        # throws an error if n_layers is less than 2 \n",
    "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n",
    "        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n",
    "        # when set to True number of nodes are decreased for subsequent layers \n",
    "        # NOTE: the order of the number of nodes doesn't matter\n",
    "        if negative_node_incrementation:\n",
    "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
    "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "            \n",
    "        # when set to False number of nodes are increased for subsequent layers\n",
    "        else:\n",
    "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
    "            nodes_increment = (last_layer_nodes + first_layer_nodes)/ (n_layers-1)\n",
    "\n",
    "        nodes = first_layer_nodes\n",
    "\n",
    "        for i in range(1, n_layers+1):\n",
    "\n",
    "            layers.append(math.ceil(nodes))\n",
    "\n",
    "            # increment nodes for next layer \n",
    "            nodes = nodes + nodes_increment\n",
    "\n",
    "        return layers\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
    "    \n",
    "    for i in range(1, n_layers+1):\n",
    "        if i==1:\n",
    "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=act_funct))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=act_funct))\n",
    "            \n",
    "            \n",
    "    # output layer \n",
    "    model.add(Dense(10, # 10 unit/neurons in output layer because we have 10 possible labels to predict  \n",
    "                    activation='softmax')) # use softmax for a label set greater than 2            \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer='adam', # adam is a good default optimizer \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # do not include model.fit() inside the create_model function\n",
    "    # KerasClassifier is expecting a complied model \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YO-x0nqt7mNh"
   },
   "source": [
    "## 1.1 Explore `create_model`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1hnjQHKW19w"
   },
   "source": [
    "The helper function `gen_layer_nodes()` which is contained inside `create_model()` <br>\n",
    "returns a list containing the number of nodes for each successive layer.<br>\n",
    "\n",
    "Let's check that `gen_layer_nodes()` behaves as expected. <br>\n",
    "In other words, we'll perform a **Unit Test!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YiPXu0p_Qco_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
    "        \"\"\"\n",
    "        Generates and returns the number of nodes in each hidden layer. \n",
    "        To be clear, this excludes the input and output layer. \n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        Number of nodes in each layer is linearly incremented. \n",
    "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_layers: int\n",
    "            Number of hidden layers\n",
    "            This values should be 2 or greater \n",
    "\n",
    "        first_layer_nodes: int\n",
    "\n",
    "        last_layer_nodes: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        layers: list of ints\n",
    "            Contains number of nodes for each layer \n",
    "        \"\"\"\n",
    "\n",
    "        # throws an error if n_layers is less than 2 \n",
    "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n",
    "        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n",
    "        # when set to True number of nodes are decreased for subsequent layers \n",
    "        # NOTE: the order of the number of nodes doesn't matter\n",
    "        if negative_node_incrementation:\n",
    "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
    "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "            #print(f'nodes increment = {nodes_increment}')\n",
    "            \n",
    "        # when set to False number of nodes are increased for subsequent layers\n",
    "        else:\n",
    "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
    "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "            #print(f'nodes increment = {nodes_increment}')\n",
    "\n",
    "        nodes = first_layer_nodes\n",
    "\n",
    "        for i in range(1, n_layers+1):\n",
    "\n",
    "            layers.append(math.ceil(nodes))\n",
    "\n",
    "            # increment nodes for next layer \n",
    "            nodes = nodes + nodes_increment\n",
    "\n",
    "        return layers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj3MrB6jXUMG"
   },
   "source": [
    "### `negative_node_incrementation = True`\n",
    "For this case we want the number of nodes to _decrease_ by a constant number for successive layers. <br>So `first_layer_nodes` must be _larger_ than `last_layer_nodes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1639006068171,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "4m4jRNllXPPG",
    "outputId": "e30bda1b-658e-40c9-8a74-dc228e6055b9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in successive layers: [500, 400, 300, 200, 100]\n"
     ]
    }
   ],
   "source": [
    "n_layers = 5\n",
    "first_layer_nodes = 500\n",
    "last_layer_nodes = 100\n",
    "negative_node_incrementation = True\n",
    "n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
    "print(f'Number of nodes in successive layers: {n_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttkaf3g9XhGr"
   },
   "source": [
    "### `negative_node_incrementation = False`\n",
    "For this case we want the number of nodes to _increase_ by a constant number for successive layers. <br>So `first_layer_nodes` must be _smaller_ than `last_layer_nodes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1639006083058,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 480
    },
    "id": "0fkrMS8bXQUo",
    "outputId": "e7f849a8-831c-45b7-98f1-d369eb32a86b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in successive layers: [100, 200, 300, 400, 500]\n"
     ]
    }
   ],
   "source": [
    "n_layers = 5\n",
    "first_layer_nodes = 100\n",
    "last_layer_nodes = 500\n",
    "negative_node_incrementation = False\n",
    "n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
    "print(f'Number of nodes in successive layers: {n_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHuB-bm5Wkpq"
   },
   "source": [
    "### OK, the Unit Test is passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO3AjVWOZ6SA"
   },
   "source": [
    "### Let's build a few models<br> \n",
    "in order to understand how `create_model()` works in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95E85Ug07mNh"
   },
   "source": [
    "### Build a model, setting `negative_node_incrementation = True` \n",
    "\n",
    "Use `create_model` to build a model. \n",
    "\n",
    "- Set `n_layers = 10` \n",
    "- Set `first_layer_nodes = 500`\n",
    "- Set `last_layer_nodes = 100`\n",
    "- Set `act_funct = \"relu\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "id": "x_1REOCY7mNi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dcf5c585f07629a03086cf57ba53615",
     "grade": false,
     "grade_id": "cell-86d63e89a21223de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use create_model to create a model \n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = create_model(n_layers=10,  first_layer_nodes=500, last_layer_nodes=100, act_funct =\"relu\", negative_node_incrementation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sYMwZQ7k7mNi",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 456)               228456    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 412)               188284    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 367)               151571    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 323)               118864    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 278)               90072     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 234)               65286     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 189)               44415     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 145)               27550     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               14600     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,322,608\n",
      "Trainable params: 1,322,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run model.summary() and make sure that you understand the model architecture that you just built \n",
    "# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUc0jfnRm-uh"
   },
   "source": [
    "### Build a model, setting `negative_node_incrementation = False` \n",
    "\n",
    "Use `create_model` to build a model. \n",
    "\n",
    "- Set `n_layers = 10` \n",
    "- Set `first_layer_nodes = 100`\n",
    "- Set `last_layer_nodes = 500`\n",
    "- Set `act_funct = \"relu\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "id": "3_-kqHQtm-ui",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dcf5c585f07629a03086cf57ba53615",
     "grade": false,
     "grade_id": "cell-86d63e89a21223de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use create_model to create a model \n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = create_model(n_layers=10,  first_layer_nodes=100, last_layer_nodes=500, act_funct =\"relu\", negative_node_incrementation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "piboKWsNm-uj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 167)               16867     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 234)               39312     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 301)               70735     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 367)               110834    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 434)               159712    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 501)               217935    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 567)               284634    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 634)               360112    \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 700)               444500    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                7010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,790,151\n",
      "Trainable params: 1,790,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run model.summary() and make sure that you understand the model architecture that you just built \n",
    "# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBH7AR9p0OXi"
   },
   "source": [
    "## 1.2 Create a grid search using `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veloj7Nnlttf"
   },
   "source": [
    "### Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3e2lhZqP7mNn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'n_layers': [2, 3],\n",
    "              'epochs': [3], \n",
    "              \"first_layer_nodes\": [500, 300],\n",
    "              \"last_layer_nodes\": [100, 50]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2Ks_MLPB7mNn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/9b73nm7x0d5bz481kpj_k3640000gn/T/ipykernel_7347/1702691071.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(create_model)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498795,
     "status": "ok",
     "timestamp": 1631204158958,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "m8GKbLJ_7mNn",
    "outputId": "cf7d9084-4042-4518-a0ac-cdbd1edf1c4a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 17:49:47.975718: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-25 17:49:47.992847: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-25 17:49:48.040106: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-25 17:49:48.041252: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-25 17:49:48.041720: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-25 17:49:48.049463: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-25 17:49:48.050665: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6644 - accuracy: 0.7994\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6497 - accuracy: 0.8019\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6463 - accuracy: 0.8022\n",
      "1247/1563 [======================>.......] - ETA: 1s - loss: 0.6744 - accuracy: 0.7914Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6460 - accuracy: 0.8048\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6441 - accuracy: 0.8016\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6459 - accuracy: 0.8024\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6500 - accuracy: 0.7993\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4464 - accuracy: 0.8652\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4419 - accuracy: 0.8659\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4421 - accuracy: 0.8667\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4380 - accuracy: 0.8677\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4447 - accuracy: 0.8626\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4439 - accuracy: 0.8641\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4461 - accuracy: 0.8642\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3619 - accuracy: 0.8903\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3532 - accuracy: 0.8922\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3556 - accuracy: 0.8926\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3494 - accuracy: 0.8929\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4582 - accuracy: 0.8660\n",
      "615/782 [======================>.......] - ETA: 0s - loss: 0.4618 - accuracy: 0.8675Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4844 - accuracy: 0.8584\n",
      " 971/1563 [=================>............] - ETA: 2s - loss: 0.3541 - accuracy: 0.8902Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4603 - accuracy: 0.8659\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4627 - accuracy: 0.8678\n",
      " 142/1563 [=>............................] - ETA: 2s - loss: 1.1128 - accuracy: 0.6514Epoch 1/3\n",
      "1062/1563 [===================>..........] - ETA: 2s - loss: 0.3546 - accuracy: 0.8907Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3592 - accuracy: 0.8892\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3606 - accuracy: 0.8880\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3659 - accuracy: 0.8887\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6553 - accuracy: 0.8009\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6571 - accuracy: 0.8033\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.4739 - accuracy: 0.8565\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4687 - accuracy: 0.8636\n",
      " 526/1563 [=========>....................] - ETA: 2s - loss: 0.4654 - accuracy: 0.8597Epoch 1/3\n",
      " 559/1563 [=========>....................] - ETA: 2s - loss: 0.4646 - accuracy: 0.8598Epoch 1/3\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4565 - accuracy: 0.8626\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6515 - accuracy: 0.8015\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6541 - accuracy: 0.7975\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4441 - accuracy: 0.8655\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4487 - accuracy: 0.8638\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6700 - accuracy: 0.7973\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6577 - accuracy: 0.7996\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6572 - accuracy: 0.7986\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4435 - accuracy: 0.8659\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4394 - accuracy: 0.8661\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3575 - accuracy: 0.8911\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4544 - accuracy: 0.8638\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3641 - accuracy: 0.8907\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4510 - accuracy: 0.8633\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4692 - accuracy: 0.8623\n",
      " 627/1563 [===========>..................] - ETA: 3s - loss: 0.3525 - accuracy: 0.8919Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3716 - accuracy: 0.8870\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3703 - accuracy: 0.8860\n",
      "782/782 [==============================] - 1s 883us/step - loss: 0.4757 - accuracy: 0.8608\n",
      "782/782 [==============================] - 1s 922us/step - loss: 0.4812 - accuracy: 0.8602\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3607 - accuracy: 0.8893\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6673 - accuracy: 0.7977\n",
      "Epoch 2/3\n",
      "   1/1563 [..............................] - ETA: 2s - loss: 0.4262 - accuracy: 0.9062Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4468 - accuracy: 0.8643\n",
      "Epoch 3/3\n",
      " 169/1563 [==>...........................] - ETA: 5s - loss: 0.3357 - accuracy: 0.8937Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3558 - accuracy: 0.8906\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.5102 - accuracy: 0.8515\n",
      "262/782 [=========>....................] - ETA: 0s - loss: 0.4650 - accuracy: 0.8653Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4643 - accuracy: 0.8669\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4474 - accuracy: 0.8661\n",
      " 501/1563 [========>.....................] - ETA: 3s - loss: 0.8427 - accuracy: 0.7381Epoch 1/3\n",
      " 531/1563 [=========>....................] - ETA: 3s - loss: 0.8288 - accuracy: 0.7422Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4541 - accuracy: 0.8625\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6587 - accuracy: 0.7986\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6584 - accuracy: 0.7961\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6791 - accuracy: 0.7982\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6732 - accuracy: 0.7957\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6651 - accuracy: 0.7969\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3661 - accuracy: 0.8872\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3713 - accuracy: 0.8869\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8668\n",
      "1066/1563 [===================>..........] - ETA: 1s - loss: 0.4626 - accuracy: 0.8586Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4598 - accuracy: 0.8608\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4671 - accuracy: 0.8581\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4525 - accuracy: 0.8618\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4544 - accuracy: 0.8604\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4589 - accuracy: 0.8607\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.7950\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3769 - accuracy: 0.8849\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3832 - accuracy: 0.8850\n",
      "782/782 [==============================] - 1s 884us/step - loss: 0.4806 - accuracy: 0.8562\n",
      "782/782 [==============================] - 1s 930us/step - loss: 0.4701 - accuracy: 0.8642\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3741 - accuracy: 0.8846\n",
      "1048/1563 [===================>..........] - ETA: 1s - loss: 0.3688 - accuracy: 0.8862Epoch 1/3\n",
      "1478/1563 [===========================>..] - ETA: 0s - loss: 0.3731 - accuracy: 0.8862Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3726 - accuracy: 0.8865\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4610 - accuracy: 0.8611\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3775 - accuracy: 0.8843\n",
      "782/782 [==============================] - 1s 980us/step - loss: 0.4800 - accuracy: 0.8589\n",
      "258/782 [========>.....................] - ETA: 0s - loss: 0.4556 - accuracy: 0.8640Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4587 - accuracy: 0.8603\n",
      "782/782 [==============================] - 1s 689us/step - loss: 0.4693 - accuracy: 0.8624\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3757 - accuracy: 0.8861\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6662 - accuracy: 0.7976\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6733 - accuracy: 0.7946\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 689us/step - loss: 0.4686 - accuracy: 0.8650\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6772 - accuracy: 0.7907\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4544 - accuracy: 0.8629\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4597 - accuracy: 0.8591\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 920us/step - loss: 0.4820 - accuracy: 0.8605\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4613 - accuracy: 0.8594\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3733 - accuracy: 0.8846\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3779 - accuracy: 0.8842\n",
      "782/782 [==============================] - 1s 756us/step - loss: 0.4676 - accuracy: 0.8587\n",
      "782/782 [==============================] - 1s 752us/step - loss: 0.4679 - accuracy: 0.8622\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3783 - accuracy: 0.8829\n",
      "782/782 [==============================] - 0s 494us/step - loss: 0.4801 - accuracy: 0.8578\n",
      "Epoch 1/3\n",
      "  41/2344 [..............................] - ETA: 2s - loss: 1.4406 - accuracy: 0.5457  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 17:50:52.988146: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344/2344 [==============================] - 3s 1ms/step - loss: 0.6147 - accuracy: 0.8138\n",
      "Epoch 2/3\n",
      "2344/2344 [==============================] - 3s 1ms/step - loss: 0.4238 - accuracy: 0.8722\n",
      "Epoch 3/3\n",
      "2344/2344 [==============================] - 3s 1ms/step - loss: 0.3491 - accuracy: 0.8934\n",
      "Best: 0.8650533358256022 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "Means: 0.8640399972597758, Stdev: 0.004030427972440491 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
      "Means: 0.8609333435694376, Stdev: 0.0031472965886562843 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "Means: 0.8650533358256022, Stdev: 0.0019936730781571197 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "Means: 0.8614933292071024, Stdev: 0.007058330871421605 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "Means: 0.8611466685930887, Stdev: 0.0008922417184341756 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n",
      "Means: 0.8598933219909668, Stdev: 0.0006930858559695144 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "Means: 0.8617733319600424, Stdev: 0.003981344385420279 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "Means: 0.8595733443895975, Stdev: 0.001919540962344798 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "CPU times: user 17.7 s, sys: 5.99 s, total: 23.6 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OfH6okqe7mNo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Inlda_0w7mNo",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 3,\n",
       " 'first_layer_nodes': 500,\n",
       " 'last_layer_nodes': 50,\n",
       " 'n_layers': 2,\n",
       " 'build_fn': <function __main__.create_model(n_layers, first_layer_nodes, last_layer_nodes, act_funct='relu', negative_node_incrementation=True)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrs3Yib17mNl"
   },
   "source": [
    "Ok, now that we've played around a bit with  `create_model`, let's build a  simpler model that we'll use to run gridsearches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvegpS1-5yYX"
   },
   "source": [
    "### Build model\n",
    "\n",
    "Use `create_model` to build a model. \n",
    "\n",
    "- Set `n_layers = 2` \n",
    "- Set `first_layer_nodes = 500`\n",
    "- Set `last_layer_nodes = 100`\n",
    "- Set `act_funct = \"relu\"`\n",
    "- Make sure that `negative_node_incrementation = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "p-NcKYRr5yYX",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ca6c5e51302fd10",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use create_model to create a model \n",
    "\n",
    "###BEGIN SOLUTION\n",
    "model = create_model(n_layers=2,  first_layer_nodes=500, last_layer_nodes=100, act_funct =\"relu\", negative_node_incrementation=True) \n",
    "\n",
    "###END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1633554004683,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "ICLd6cYN5yYY",
    "outputId": "0e08e125-2923-4755-a562-df429d0fcab6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 443,610\n",
      "Trainable params: 443,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run model.summary() and make sure that you understand the model architecture that you just built \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KwY6GFo85yYY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'n_layers': [2, 3],\n",
    "              'epochs': [3], \n",
    "              \"first_layer_nodes\": [500, 300],\n",
    "              \"last_layer_nodes\": [100, 50]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8a0iHBqJ5yYY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/9b73nm7x0d5bz481kpj_k3640000gn/T/ipykernel_7347/1702691071.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(create_model)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304738,
     "status": "ok",
     "timestamp": 1633554309410,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "kxpuM3g15yYZ",
    "outputId": "2ad0da1d-39be-4980-9b6c-02254002afa8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "   1/1563 [..............................] - ETA: 4:26 - loss: 2.4381 - accuracy: 0.0938Epoch 1/3\n",
      "   1/1563 [..............................] - ETA: 5:00 - loss: 2.3811 - accuracy: 0.0625Epoch 1/3\n",
      "   9/1563 [..............................] - ETA: 10s - loss: 2.0805 - accuracy: 0.3021 Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6645 - accuracy: 0.7989\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6478 - accuracy: 0.8035\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6485 - accuracy: 0.8023\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6469 - accuracy: 0.8053\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6531 - accuracy: 0.7999\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6513 - accuracy: 0.7995\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6456 - accuracy: 0.8019\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4505 - accuracy: 0.8655\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.4403 - accuracy: 0.8668\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4397 - accuracy: 0.8664\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.4401 - accuracy: 0.8664\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4439 - accuracy: 0.8642\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4460 - accuracy: 0.8642\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4412 - accuracy: 0.8635\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3623 - accuracy: 0.8899\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3542 - accuracy: 0.8907\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3514 - accuracy: 0.8932\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3551 - accuracy: 0.8922\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4792 - accuracy: 0.8617\n",
      " 546/1563 [=========>....................] - ETA: 4s - loss: 0.3525 - accuracy: 0.8898Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4603 - accuracy: 0.8651\n",
      " 626/1563 [===========>..................] - ETA: 3s - loss: 0.3571 - accuracy: 0.8881Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3615 - accuracy: 0.8884\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3645 - accuracy: 0.8869\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3558 - accuracy: 0.8899\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6596 - accuracy: 0.8008\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4554 - accuracy: 0.8642\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4575 - accuracy: 0.8656\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6626 - accuracy: 0.7992\n",
      "727/782 [==========================>...] - ETA: 0s - loss: 0.4713 - accuracy: 0.8597Epoch 2/3\n",
      "544/782 [===================>..........] - ETA: 0s - loss: 0.4553 - accuracy: 0.8670Epoch 1/3\n",
      "557/782 [====================>.........] - ETA: 0s - loss: 0.4562 - accuracy: 0.8671Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4718 - accuracy: 0.8597\n",
      "  61/1563 [>.............................] - ETA: 5s - loss: 1.3081 - accuracy: 0.5743Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4561 - accuracy: 0.8669\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.8638\n",
      " 615/1563 [==========>...................] - ETA: 2s - loss: 0.4501 - accuracy: 0.8614Epoch 1/3\n",
      " 411/1563 [======>.......................] - ETA: 3s - loss: 0.8626 - accuracy: 0.7312Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4449 - accuracy: 0.8642\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4484 - accuracy: 0.8642\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6640 - accuracy: 0.8002\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6639 - accuracy: 0.7975\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6518 - accuracy: 0.8014\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6477 - accuracy: 0.8011\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6494 - accuracy: 0.8008\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3572 - accuracy: 0.8908\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4529 - accuracy: 0.8628\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3625 - accuracy: 0.8887\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4488 - accuracy: 0.8638\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4668 - accuracy: 0.8628\n",
      " 646/1563 [===========>..................] - ETA: 2s - loss: 0.3602 - accuracy: 0.8909Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4400 - accuracy: 0.8655\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4437 - accuracy: 0.8651\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4413 - accuracy: 0.8651\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3705 - accuracy: 0.8879\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3664 - accuracy: 0.8906\n",
      "782/782 [==============================] - 1s 773us/step - loss: 0.4876 - accuracy: 0.8569\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6668 - accuracy: 0.7975\n",
      "Epoch 2/3\n",
      " 446/1563 [=======>......................] - ETA: 3s - loss: 0.3592 - accuracy: 0.8899Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4674 - accuracy: 0.8617\n",
      "1081/1563 [===================>..........] - ETA: 1s - loss: 0.3591 - accuracy: 0.8904Epoch 1/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4576 - accuracy: 0.8628\n",
      "1315/1563 [========================>.....] - ETA: 0s - loss: 0.3580 - accuracy: 0.8908Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.3557 - accuracy: 0.8917\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3617 - accuracy: 0.8896\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6575 - accuracy: 0.8000\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3610 - accuracy: 0.8895\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4597 - accuracy: 0.8660\n",
      " 369/1563 [======>.......................] - ETA: 3s - loss: 0.4583 - accuracy: 0.8603Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4571 - accuracy: 0.8645\n",
      " 505/1563 [========>.....................] - ETA: 2s - loss: 0.4541 - accuracy: 0.8602Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6631 - accuracy: 0.7957\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3759 - accuracy: 0.8867\n",
      "782/782 [==============================] - 1s 922us/step - loss: 0.4521 - accuracy: 0.8672\n",
      "681/782 [=========================>....] - ETA: 0s - loss: 0.4503 - accuracy: 0.8653Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4522 - accuracy: 0.8647\n",
      " 178/1563 [==>...........................] - ETA: 1s - loss: 1.0859 - accuracy: 0.6643Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4552 - accuracy: 0.8611\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 913us/step - loss: 0.4618 - accuracy: 0.8608\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.7939\n",
      "Epoch 2/3\n",
      "1321/1563 [========================>.....] - ETA: 0s - loss: 0.6906 - accuracy: 0.7888Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6635 - accuracy: 0.7970\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6900 - accuracy: 0.7904\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4588 - accuracy: 0.8594\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6767 - accuracy: 0.7954\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4626 - accuracy: 0.8607\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3783 - accuracy: 0.8846\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6743 - accuracy: 0.7945\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4780 - accuracy: 0.8523\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4605 - accuracy: 0.8595\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4690 - accuracy: 0.8582\n",
      "Epoch 3/3\n",
      "  63/1563 [>.............................] - ETA: 5s - loss: 0.3849 - accuracy: 0.8780Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4639 - accuracy: 0.8600\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3806 - accuracy: 0.8833\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3737 - accuracy: 0.8845\n",
      "782/782 [==============================] - 1s 962us/step - loss: 0.4675 - accuracy: 0.8611\n",
      " 871/1563 [===============>..............] - ETA: 2s - loss: 0.3779 - accuracy: 0.8839Epoch 1/3\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.8661\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3845 - accuracy: 0.8831\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3829 - accuracy: 0.8837\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4558 - accuracy: 0.8620\n",
      "1427/1563 [==========================>...] - ETA: 0s - loss: 0.3826 - accuracy: 0.8829Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3839 - accuracy: 0.8825\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6655 - accuracy: 0.7966\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 816us/step - loss: 0.4699 - accuracy: 0.8615\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6739 - accuracy: 0.7937\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3770 - accuracy: 0.8841\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4551 - accuracy: 0.8609\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 804us/step - loss: 0.4661 - accuracy: 0.8598\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.4604 - accuracy: 0.8586\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3727 - accuracy: 0.8841\n",
      "782/782 [==============================] - 1s 682us/step - loss: 0.4758 - accuracy: 0.8584\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3783 - accuracy: 0.8843\n",
      "782/782 [==============================] - 0s 483us/step - loss: 0.4801 - accuracy: 0.8565\n",
      "782/782 [==============================] - 0s 415us/step - loss: 0.4816 - accuracy: 0.8613\n",
      "782/782 [==============================] - 0s 417us/step - loss: 0.4606 - accuracy: 0.8664\n",
      "Epoch 1/3\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 0.6028 - accuracy: 0.8157\n",
      "Epoch 2/3\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 0.4199 - accuracy: 0.8713\n",
      "Epoch 3/3\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 0.3462 - accuracy: 0.8935\n",
      "Best: 0.8650533358256022 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "Means: 0.8636399904886881, Stdev: 0.0014359330518637044 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
      "Means: 0.8634533286094666, Stdev: 0.0029495920394771143 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "Means: 0.8633866707483927, Stdev: 0.0016304743961677948 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "Means: 0.8650533358256022, Stdev: 0.0006485516098492163 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "Means: 0.8616533478101095, Stdev: 0.004236019414573695 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n",
      "Means: 0.8599599997202555, Stdev: 0.0057193818675697556 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "Means: 0.8629466692606608, Stdev: 0.002472099430967283 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "Means: 0.8582266569137573, Stdev: 0.001347517329510481 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "CPU times: user 24.3 s, sys: 8.9 s, total: 33.2 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TIlpwjag5yYZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1633554309413,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "MFvMxmr85yYZ",
    "outputId": "a4320b01-498e-41af-834d-4caeb8acf28a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 3,\n",
       " 'first_layer_nodes': 500,\n",
       " 'last_layer_nodes': 50,\n",
       " 'n_layers': 3,\n",
       " 'build_fn': <function __main__.create_model(n_layers, first_layer_nodes, last_layer_nodes, act_funct='relu', negative_node_incrementation=True)>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6azV65Nb7mNo"
   },
   "source": [
    "-----\n",
    "\n",
    "# Experiment 2: Run the Gridsearch Algorithms \n",
    "\n",
    "In this section, we are going to use the same model and dataset in order to benchmark 3 different gridsearch approaches: \n",
    "\n",
    "- Gridsearch\n",
    "- Random Search\n",
    "- Bayesian Optimization. \n",
    "\n",
    "\n",
    "Our goal in this experiment is two-fold. We want to see which appraoch \n",
    "\n",
    "- Scores the highest accuracy\n",
    "- Has the shortest run time \n",
    "\n",
    "We want to see how these 3 gridsearch approaches handle these trade-offs and to give you a sense of those trades offs.\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "`Gridsearch` will train a model on every single unique hyperparameter combination, this guarantees that you'll get the highest possible accuracy from your parameter set but your gridsearch might have a very long run-time. \n",
    "\n",
    "`Random Search` will randomly sample from your parameter set which, depending on how many samples, the run-time might be significantly cut down but you might or might not sample the parameters that correspond to the heightest possible accuracies. \n",
    "\n",
    "`Bayesian Optimization` has a bit of intelligence built into it's search algorithm but you do need to manually select some parameters which may greatly influence the model learning outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X41u_hls7mNp"
   },
   "source": [
    "-------\n",
    "### Build our hyperparameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1631141004011,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "PYE7rTku7mNp",
    "outputId": "10c8a8f5-fd6d-46fb-e09e-032b0f13ef3a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relu'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build out our hyperparameter dictionary \n",
    "hp = HyperParameters()\n",
    "hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n",
    "hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqjp2kHD7mNu"
   },
   "source": [
    "---------\n",
    "## 2.1 Gridsearch Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsNW4rJp7mNu"
   },
   "source": [
    "### Populate a `sklearn` compatible parameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vJQFKoyL7mNu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build out our hyperparameter dictionary \n",
    "hyper_parameters = {\n",
    "    # BUG Fix: cast array as list otherwise GridSearchCV will throw error\n",
    "    \"units\": np.arange(32, 512, 32).tolist(),\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
    "    \"activation\":[\"relu\", \"sigmoid\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RcxV58iC7mNu",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': [32,\n",
       "  64,\n",
       "  96,\n",
       "  128,\n",
       "  160,\n",
       "  192,\n",
       "  224,\n",
       "  256,\n",
       "  288,\n",
       "  320,\n",
       "  352,\n",
       "  384,\n",
       "  416,\n",
       "  448,\n",
       "  480],\n",
       " 'learning_rate': [0.1, 0.01, 0.001],\n",
       " 'activation': ['relu', 'sigmoid']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOoMg9Ao7mNv"
   },
   "source": [
    "### Build a `sklearn` compatible model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "EZFVl-I-7mNv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(units, learning_rate, activation):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a complie keras model ready for keras-tuner gridsearch algorithms \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # hidden layer\n",
    "    model.add(Dense(units, activation=activation))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqYmn3QFsqZ_"
   },
   "source": [
    "### Apply the \"wrapper\" to make the model compatible with `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ABSzrTrH7mNw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/9b73nm7x0d5bz481kpj_k3640000gn/T/ipykernel_7347/3788592660.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = build_model)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tTawllrN7mNw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.8745 - accuracy: 0.3155\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.9381 - accuracy: 0.2896\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 2.0122 - accuracy: 0.2421\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.9683 - accuracy: 0.2681\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 2.1380 - accuracy: 0.2124\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.9087 - accuracy: 0.3091\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9852 - accuracy: 0.2844\n",
      "782/782 [==============================] - 1s 835us/step - loss: 1.9876 - accuracy: 0.2588\n",
      "782/782 [==============================] - 1s 819us/step - loss: 2.1179 - accuracy: 0.2777\n",
      "782/782 [==============================] - 1s 825us/step - loss: 1.9711 - accuracy: 0.2422\n",
      "782/782 [==============================] - 1s 850us/step - loss: 2.1239 - accuracy: 0.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 908us/step - loss: 2.1900 - accuracy: 0.1502\n",
      "782/782 [==============================] - 1s 962us/step - loss: 1.8120 - accuracy: 0.3171\n",
      "782/782 [==============================] - 1s 849us/step - loss: 2.0232 - accuracy: 0.2302\n",
      "  50/1563 [..............................] - ETA: 3s - loss: 4.0835 - accuracy: 0.254450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 2.0241 - accuracy: 0.2664\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9689 - accuracy: 0.2970\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9392 - accuracy: 0.3168\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8926 - accuracy: 0.3307\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0665 - accuracy: 0.2654\n",
      "782/782 [==============================] - 1s 790us/step - loss: 1.9825 - accuracy: 0.2614\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9784 - accuracy: 0.3225\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8766 - accuracy: 0.3418\n",
      "782/782 [==============================] - 1s 834us/step - loss: 2.0936 - accuracy: 0.2010\n",
      "472/782 [=================>............] - ETA: 0s - loss: 1.9974 - accuracy: 0.3004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 971us/step - loss: 1.9138 - accuracy: 0.3231\n",
      "782/782 [==============================] - 1s 973us/step - loss: 1.9753 - accuracy: 0.2975\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 2.0057 - accuracy: 0.2412\n",
      "586/782 [=====================>........] - ETA: 0s - loss: 1.8198 - accuracy: 0.3435"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 994us/step - loss: 1.8062 - accuracy: 0.3449  \n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8748 - accuracy: 0.3057\n",
      " 186/1563 [==>...........................] - ETA: 2s - loss: 2.3989 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9958 - accuracy: 0.3094\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.2375 - accuracy: 0.1931\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9825 - accuracy: 0.3219\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8827 - accuracy: 0.3864\n",
      "782/782 [==============================] - 1s 821us/step - loss: 2.2528 - accuracy: 0.1384\n",
      "302/782 [==========>...................] - ETA: 0s - loss: 1.9174 - accuracy: 0.2861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9047 - accuracy: 0.3380\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9803 - accuracy: 0.3387\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 2.1783 - accuracy: 0.1529\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0394 - accuracy: 0.3175\n",
      "782/782 [==============================] - 1s 962us/step - loss: 1.9255 - accuracy: 0.2865\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 1.8259 - accuracy: 0.3264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9560 - accuracy: 0.2984\n",
      " 129/1563 [=>............................] - ETA: 1s - loss: 3.3969 - accuracy: 0.3789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9519 - accuracy: 0.3326\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8227 - accuracy: 0.3257\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9119 - accuracy: 0.3035\n",
      " 351/1563 [=====>........................] - ETA: 1s - loss: 2.4182 - accuracy: 0.3625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 353/1563 [=====>........................] - ETA: 2s - loss: 2.9432 - accuracy: 0.3402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0736 - accuracy: 0.2956\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0861 - accuracy: 0.2846\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0702 - accuracy: 0.2924\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9686 - accuracy: 0.2514\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.1528 - accuracy: 0.3172\n",
      "510/782 [==================>...........] - ETA: 0s - loss: 2.0567 - accuracy: 0.272803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 979us/step - loss: 1.9934 - accuracy: 0.2277\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 2.0549 - accuracy: 0.2733\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0518 - accuracy: 0.3211\n",
      "1517/1563 [============================>.] - ETA: 0s - loss: 1.8984 - accuracy: 0.3881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7944 - accuracy: 0.3267\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9050 - accuracy: 0.3841\n",
      " 117/1563 [=>............................] - ETA: 1s - loss: 4.2707 - accuracy: 0.4119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0477 - accuracy: 0.3482\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9821 - accuracy: 0.2468\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9390 - accuracy: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 878us/step - loss: 1.9053 - accuracy: 0.3029\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9733 - accuracy: 0.3983\n",
      "1270/1563 [=======================>......] - ETA: 0s - loss: 2.0927 - accuracy: 0.3434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0722 - accuracy: 0.3362\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9990 - accuracy: 0.2622\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0553 - accuracy: 0.3443\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1306 - accuracy: 0.2577\n",
      "323/782 [===========>..................] - ETA: 0s - loss: 1.9862 - accuracy: 0.2691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9818 - accuracy: 0.2689\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1514 - accuracy: 0.2813\n",
      "782/782 [==============================] - 1s 994us/step - loss: 2.0074 - accuracy: 0.2307\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9337 - accuracy: 0.3210\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.1467 - accuracy: 0.2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 2.0064 - accuracy: 0.2309\n",
      "1262/1563 [=======================>......] - ETA: 0s - loss: 2.0721 - accuracy: 0.3588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 2.0688 - accuracy: 0.2078\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0283 - accuracy: 0.3495\n",
      " 305/1563 [====>.........................] - ETA: 2s - loss: 3.3288 - accuracy: 0.3662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8332 - accuracy: 0.3179\n",
      " 986/1563 [=================>............] - ETA: 1s - loss: 2.2672 - accuracy: 0.3229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9756 - accuracy: 0.3529\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9475 - accuracy: 0.2045\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.1129 - accuracy: 0.3733\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0297 - accuracy: 0.3234\n",
      "1543/1563 [============================>.] - ETA: 0s - loss: 2.1224 - accuracy: 0.3169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.1224 - accuracy: 0.3163\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.1957 - accuracy: 0.3098\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9407 - accuracy: 0.2850\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9986 - accuracy: 0.2715\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9333 - accuracy: 0.2984\n",
      "   1/1563 [..............................] - ETA: 3:28 - loss: 2.4326 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 198/1563 [==>...........................] - ETA: 2s - loss: 4.5208 - accuracy: 0.4020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0202 - accuracy: 0.3474\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9235 - accuracy: 0.2748\n",
      "1384/1563 [=========================>....] - ETA: 0s - loss: 2.1068 - accuracy: 0.3595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0916 - accuracy: 0.3532\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8202 - accuracy: 0.3254\n",
      " 643/1563 [===========>..................] - ETA: 2s - loss: 2.5400 - accuracy: 0.3616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7883 - accuracy: 0.7606\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8527 - accuracy: 0.2974\n",
      "1455/1563 [==========================>...] - ETA: 0s - loss: 2.1806 - accuracy: 0.3361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7884 - accuracy: 0.7574\n",
      "782/782 [==============================] - 1s 684us/step - loss: 0.7410 - accuracy: 0.7749\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1634 - accuracy: 0.3299\n",
      "1253/1563 [=======================>......] - ETA: 0s - loss: 2.2815 - accuracy: 0.3445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8004 - accuracy: 0.7573\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.2021 - accuracy: 0.3373\n",
      "782/782 [==============================] - 0s 531us/step - loss: 0.6974 - accuracy: 0.7901\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.1565 - accuracy: 0.3328\n",
      "378/782 [=============>................] - ETA: 0s - loss: 1.8878 - accuracy: 0.2841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9142 - accuracy: 0.2884\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7653 - accuracy: 0.7716\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9965 - accuracy: 0.3432\n",
      "782/782 [==============================] - 1s 602us/step - loss: 0.7058 - accuracy: 0.7820\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7555 - accuracy: 0.7703\n",
      "169/782 [=====>........................] - ETA: 0s - loss: 0.6828 - accuracy: 0.7866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8010 - accuracy: 0.3121\n",
      " 205/1563 [==>...........................] - ETA: 2s - loss: 0.9917 - accuracy: 0.6858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 918us/step - loss: 0.6889 - accuracy: 0.7890\n",
      "782/782 [==============================] - 1s 944us/step - loss: 0.6782 - accuracy: 0.8004\n",
      "1120/1563 [====================>.........] - ETA: 0s - loss: 0.7759 - accuracy: 0.7640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7492 - accuracy: 0.7735\n",
      "782/782 [==============================] - 1s 714us/step - loss: 0.6332 - accuracy: 0.8112\n",
      "   1/1563 [..............................] - ETA: 3:11 - loss: 2.4872 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7482 - accuracy: 0.7752\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7397 - accuracy: 0.7757\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7445 - accuracy: 0.7758\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7563 - accuracy: 0.7701\n",
      "782/782 [==============================] - 1s 821us/step - loss: 0.6913 - accuracy: 0.7944\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7407 - accuracy: 0.7764\n",
      "782/782 [==============================] - 1s 817us/step - loss: 0.6366 - accuracy: 0.8098\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.7456 - accuracy: 0.7744\n",
      "716/782 [==========================>...] - ETA: 0s - loss: 0.6757 - accuracy: 0.7976  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 792us/step - loss: 0.6790 - accuracy: 0.7965\n",
      "782/782 [==============================] - 1s 923us/step - loss: 0.6363 - accuracy: 0.8093\n",
      " 143/1563 [=>............................] - ETA: 1s - loss: 1.0500 - accuracy: 0.6772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 981us/step - loss: 0.6802 - accuracy: 0.7984\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6975 - accuracy: 0.7988\n",
      " 219/1563 [===>..........................] - ETA: 1s - loss: 0.9648 - accuracy: 0.6995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 590/1563 [==========>...................] - ETA: 1s - loss: 0.8395 - accuracy: 0.7428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7405 - accuracy: 0.7769\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7481 - accuracy: 0.7745\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7474 - accuracy: 0.7729\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7412 - accuracy: 0.7784\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7339 - accuracy: 0.7786\n",
      "782/782 [==============================] - 1s 796us/step - loss: 0.6495 - accuracy: 0.8087\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.7422 - accuracy: 0.7761\n",
      "782/782 [==============================] - 1s 687us/step - loss: 0.6459 - accuracy: 0.8054\n",
      "645/782 [=======================>......] - ETA: 0s - loss: 0.6969 - accuracy: 0.7899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 822us/step - loss: 0.6922 - accuracy: 0.7906\n",
      "782/782 [==============================] - 1s 754us/step - loss: 0.6570 - accuracy: 0.8129\n",
      "   1/1563 [..............................] - ETA: 3:08 - loss: 2.4322 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.7370 - accuracy: 0.7774\n",
      "782/782 [==============================] - 1s 957us/step - loss: 0.6754 - accuracy: 0.7938\n",
      "782/782 [==============================] - 1s 726us/step - loss: 0.6551 - accuracy: 0.8081\n",
      "782/782 [==============================] - 1s 922us/step - loss: 0.6464 - accuracy: 0.8075\n",
      " 562/1563 [=========>....................] - ETA: 1s - loss: 0.8375 - accuracy: 0.7415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 656/1563 [===========>..................] - ETA: 1s - loss: 0.8217 - accuracy: 0.7478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7358 - accuracy: 0.7769\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7369 - accuracy: 0.7772\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7377 - accuracy: 0.7772\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7345 - accuracy: 0.7763\n",
      "782/782 [==============================] - 1s 932us/step - loss: 0.6804 - accuracy: 0.8043\n",
      "782/782 [==============================] - 1s 889us/step - loss: 0.6461 - accuracy: 0.8110\n",
      "1182/1563 [=====================>........] - ETA: 0s - loss: 0.7632 - accuracy: 0.7705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6615 - accuracy: 0.8031  \n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6541 - accuracy: 0.8034\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7343 - accuracy: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53/782 [=>............................] - ETA: 0s - loss: 0.6596 - accuracy: 0.8107 0  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7379 - accuracy: 0.7789\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7494 - accuracy: 0.7739\n",
      "782/782 [==============================] - 1s 982us/step - loss: 0.6818 - accuracy: 0.8033\n",
      "782/782 [==============================] - 1s 963us/step - loss: 0.6756 - accuracy: 0.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 618/1563 [==========>...................] - ETA: 2s - loss: 0.8223 - accuracy: 0.7474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7373 - accuracy: 0.7816\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7364 - accuracy: 0.7811\n",
      "782/782 [==============================] - 1s 908us/step - loss: 0.6698 - accuracy: 0.8071\n",
      " 818/1563 [==============>...............] - ETA: 1s - loss: 0.8058 - accuracy: 0.7557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7409 - accuracy: 0.7765\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7399 - accuracy: 0.7780\n",
      "782/782 [==============================] - 1s 987us/step - loss: 0.6430 - accuracy: 0.8102\n",
      "782/782 [==============================] - 1s 783us/step - loss: 0.6990 - accuracy: 0.8006\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7453 - accuracy: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7431 - accuracy: 0.7745\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.8008\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6725 - accuracy: 0.7993\n",
      "782/782 [==============================] - 1s 982us/step - loss: 0.6805 - accuracy: 0.8016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  63/1563 [>.............................] - ETA: 2s - loss: 1.1755 - accuracy: 0.6394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 129/1563 [=>............................] - ETA: 3s - loss: 1.0393 - accuracy: 0.6846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.7026 - accuracy: 0.7995\n",
      " 311/1563 [====>.........................] - ETA: 3s - loss: 0.9105 - accuracy: 0.7237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7446 - accuracy: 0.7773\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6654 - accuracy: 0.8052\n",
      " 912/1563 [================>.............] - ETA: 1s - loss: 0.7949 - accuracy: 0.7599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7485 - accuracy: 0.7752\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7404 - accuracy: 0.7783\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6918 - accuracy: 0.7942\n",
      " 617/1563 [==========>...................] - ETA: 2s - loss: 0.8302 - accuracy: 0.7471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7508 - accuracy: 0.7758\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6486 - accuracy: 0.8108\n",
      "1250/1563 [======================>.......] - ETA: 0s - loss: 0.7688 - accuracy: 0.7709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7471 - accuracy: 0.7745\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7414 - accuracy: 0.7794\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6566 - accuracy: 0.8011\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7428 - accuracy: 0.7791\n",
      "782/782 [==============================] - 1s 970us/step - loss: 0.6931 - accuracy: 0.7954\n",
      "   1/1563 [..............................] - ETA: 3:24 - loss: 2.4400 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 117/1563 [=>............................] - ETA: 2s - loss: 1.1146 - accuracy: 0.6736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6657 - accuracy: 0.8013\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7463 - accuracy: 0.7757\n",
      "782/782 [==============================] - 1s 985us/step - loss: 0.6560 - accuracy: 0.8071\n",
      " 639/1563 [===========>..................] - ETA: 2s - loss: 0.8365 - accuracy: 0.7507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6509 - accuracy: 0.8047\n",
      " 902/1563 [================>.............] - ETA: 1s - loss: 0.7943 - accuracy: 0.7624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7435 - accuracy: 0.7776\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7493 - accuracy: 0.7771\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8807 - accuracy: 0.7378\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6697 - accuracy: 0.8011\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7522 - accuracy: 0.7754\n",
      "  1/782 [..............................] - ETA: 35s - loss: 0.5970 - accuracy: 0.84384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8830 - accuracy: 0.7353\n",
      "782/782 [==============================] - 1s 741us/step - loss: 0.7264 - accuracy: 0.7844\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7446 - accuracy: 0.7751\n",
      "156/782 [====>.........................] - ETA: 0s - loss: 0.6501 - accuracy: 0.8035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6643 - accuracy: 0.8056\n",
      "449/782 [================>.............] - ETA: 0s - loss: 0.6501 - accuracy: 0.8031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 843us/step - loss: 0.7224 - accuracy: 0.7940\n",
      "1242/1563 [======================>.......] - ETA: 0s - loss: 0.7616 - accuracy: 0.7720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6525 - accuracy: 0.8042\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6737 - accuracy: 0.8000\n",
      " 479/1563 [========>.....................] - ETA: 1s - loss: 1.0071 - accuracy: 0.6983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 621/1563 [==========>...................] - ETA: 1s - loss: 0.9550 - accuracy: 0.7146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7438 - accuracy: 0.7787\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8643 - accuracy: 0.7435\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8084 - accuracy: 0.7606\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8041 - accuracy: 0.7647\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.8030\n",
      "782/782 [==============================] - 1s 689us/step - loss: 0.6559 - accuracy: 0.8078\n",
      "782/782 [==============================] - 1s 654us/step - loss: 0.7142 - accuracy: 0.7916\n",
      "1304/1563 [========================>.....] - ETA: 0s - loss: 0.8028 - accuracy: 0.7621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7904 - accuracy: 0.7648\n",
      " 45/782 [>.............................] - ETA: 0s - loss: 0.6494 - accuracy: 0.8174 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 882us/step - loss: 0.6576 - accuracy: 0.8092\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7770 - accuracy: 0.7707\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7695 - accuracy: 0.7714\n",
      "707/782 [==========================>...] - ETA: 0s - loss: 0.6359 - accuracy: 0.8136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 963us/step - loss: 0.6383 - accuracy: 0.8127\n",
      "425/782 [===============>..............] - ETA: 0s - loss: 0.6334 - accuracy: 0.8154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 878us/step - loss: 0.6167 - accuracy: 0.8188\n",
      "782/782 [==============================] - 1s 820us/step - loss: 0.6241 - accuracy: 0.8200\n",
      " 968/1563 [=================>............] - ETA: 0s - loss: 0.8203 - accuracy: 0.7561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 106/1563 [=>............................] - ETA: 1s - loss: 1.2680 - accuracy: 0.5958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7736 - accuracy: 0.7702\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7467 - accuracy: 0.7781\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7450 - accuracy: 0.7794\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7383 - accuracy: 0.7811\n",
      "782/782 [==============================] - 1s 771us/step - loss: 0.6214 - accuracy: 0.8182\n",
      "782/782 [==============================] - 1s 815us/step - loss: 0.5954 - accuracy: 0.8244\n",
      "782/782 [==============================] - 1s 839us/step - loss: 0.6086 - accuracy: 0.8214\n",
      " 901/1563 [================>.............] - ETA: 1s - loss: 0.8138 - accuracy: 0.7569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7235 - accuracy: 0.7870\n",
      "782/782 [==============================] - 1s 884us/step - loss: 0.5906 - accuracy: 0.8248\n",
      " 365/1563 [======>.......................] - ETA: 1s - loss: 0.9534 - accuracy: 0.7107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7266 - accuracy: 0.7828\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7299 - accuracy: 0.7826\n",
      "782/782 [==============================] - 1s 744us/step - loss: 0.5835 - accuracy: 0.8331\n",
      "782/782 [==============================] - 1s 761us/step - loss: 0.5847 - accuracy: 0.8286\n",
      "1142/1563 [====================>.........] - ETA: 0s - loss: 0.7705 - accuracy: 0.7711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1257/1563 [=======================>......] - ETA: 0s - loss: 0.7550 - accuracy: 0.7761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7195 - accuracy: 0.7876\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7099 - accuracy: 0.7884\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.7153 - accuracy: 0.7869\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7059 - accuracy: 0.7913\n",
      "782/782 [==============================] - 1s 928us/step - loss: 0.5759 - accuracy: 0.8284\n",
      "782/782 [==============================] - 1s 933us/step - loss: 0.5873 - accuracy: 0.8279\n",
      "782/782 [==============================] - 1s 914us/step - loss: 0.5715 - accuracy: 0.8292\n",
      "782/782 [==============================] - 1s 783us/step - loss: 0.5834 - accuracy: 0.8278\n",
      " 729/1563 [============>.................] - ETA: 1s - loss: 0.8225 - accuracy: 0.7561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042/1563 [===================>..........] - ETA: 0s - loss: 0.7624 - accuracy: 0.7749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 946us/step - loss: 0.5633 - accuracy: 0.8316\n",
      " 430/1563 [=======>......................] - ETA: 2s - loss: 0.9150 - accuracy: 0.7245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7070 - accuracy: 0.7906\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7022 - accuracy: 0.7925\n",
      "782/782 [==============================] - 1s 881us/step - loss: 0.5868 - accuracy: 0.8266\n",
      "1011/1563 [==================>...........] - ETA: 1s - loss: 0.7704 - accuracy: 0.7703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 912us/step - loss: 0.5733 - accuracy: 0.8336\n",
      "1189/1563 [=====================>........] - ETA: 0s - loss: 0.7446 - accuracy: 0.7782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6999 - accuracy: 0.7928\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7021 - accuracy: 0.7918\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7036 - accuracy: 0.7890\n",
      "782/782 [==============================] - 1s 906us/step - loss: 0.5542 - accuracy: 0.8337\n",
      "782/782 [==============================] - 1s 936us/step - loss: 0.5575 - accuracy: 0.8316\n",
      "782/782 [==============================] - 1s 994us/step - loss: 0.5676 - accuracy: 0.8330\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6899 - accuracy: 0.7933\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6896 - accuracy: 0.7964\n",
      " 739/1563 [=============>................] - ETA: 1s - loss: 0.7977 - accuracy: 0.7613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 325/1563 [=====>........................] - ETA: 2s - loss: 0.9199 - accuracy: 0.7202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 894us/step - loss: 0.5548 - accuracy: 0.8381\n",
      " 508/1563 [========>.....................] - ETA: 2s - loss: 0.8379 - accuracy: 0.7452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6920 - accuracy: 0.7938\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6846 - accuracy: 0.7962\n",
      "782/782 [==============================] - 1s 985us/step - loss: 0.5457 - accuracy: 0.8399\n",
      "782/782 [==============================] - 1s 915us/step - loss: 0.5443 - accuracy: 0.8380\n",
      "1086/1563 [===================>..........] - ETA: 1s - loss: 0.7377 - accuracy: 0.7780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.8377\n",
      "1326/1563 [========================>.....] - ETA: 0s - loss: 0.7103 - accuracy: 0.7864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6901 - accuracy: 0.7942\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6852 - accuracy: 0.7942\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6841 - accuracy: 0.7971\n",
      "782/782 [==============================] - 1s 911us/step - loss: 0.5571 - accuracy: 0.8380\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6747 - accuracy: 0.7962\n",
      " 786/1563 [==============>...............] - ETA: 1s - loss: 0.7678 - accuracy: 0.7704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 978us/step - loss: 0.5404 - accuracy: 0.8429\n",
      "1265/1563 [=======================>......] - ETA: 0s - loss: 0.7039 - accuracy: 0.7901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6837 - accuracy: 0.7950\n",
      "782/782 [==============================] - 1s 814us/step - loss: 0.5558 - accuracy: 0.8392\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6760 - accuracy: 0.7995\n",
      " 118/1563 [=>............................] - ETA: 2s - loss: 1.1052 - accuracy: 0.6565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6766 - accuracy: 0.7988\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.8371\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.8388\n",
      "219/782 [=======>......................] - ETA: 0s - loss: 0.5381 - accuracy: 0.8403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.8401\n",
      "  71/1563 [>.............................] - ETA: 2s - loss: 1.2612 - accuracy: 0.6144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.8446\n",
      " 293/1563 [====>.........................] - ETA: 3s - loss: 0.9543 - accuracy: 0.7163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6780 - accuracy: 0.7979\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6765 - accuracy: 0.7996\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6745 - accuracy: 0.7985\n",
      "782/782 [==============================] - 1s 935us/step - loss: 0.5295 - accuracy: 0.8420\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6684 - accuracy: 0.8014\n",
      "1367/1563 [=========================>....] - ETA: 0s - loss: 0.6809 - accuracy: 0.7970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.8420\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6707 - accuracy: 0.8016\n",
      "1439/1563 [==========================>...] - ETA: 0s - loss: 0.6746 - accuracy: 0.7986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5469 - accuracy: 0.8392\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6643 - accuracy: 0.8015\n",
      " 228/1563 [===>..........................] - ETA: 3s - loss: 0.9688 - accuracy: 0.7057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6668 - accuracy: 0.8017\n",
      "782/782 [==============================] - 1s 987us/step - loss: 0.5446 - accuracy: 0.8346\n",
      " 564/1563 [=========>....................] - ETA: 2s - loss: 0.8079 - accuracy: 0.7549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.8348\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5285 - accuracy: 0.8416\n",
      "515/782 [==================>...........] - ETA: 0s - loss: 0.5306 - accuracy: 0.8439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.8458\n",
      " 368/1563 [======>.......................] - ETA: 1s - loss: 1.2669 - accuracy: 0.5814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1211 - accuracy: 0.6385\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6689 - accuracy: 0.8002\n",
      "782/782 [==============================] - 1s 672us/step - loss: 1.0447 - accuracy: 0.6816\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1409 - accuracy: 0.6365\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1614 - accuracy: 0.6248\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6643 - accuracy: 0.8031\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6653 - accuracy: 0.8015\n",
      "432/782 [===============>..............] - ETA: 0s - loss: 1.1973 - accuracy: 0.6293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1392 - accuracy: 0.6399\n",
      "782/782 [==============================] - 1s 577us/step - loss: 1.0595 - accuracy: 0.6779\n",
      "782/782 [==============================] - 1s 597us/step - loss: 1.1847 - accuracy: 0.6308\n",
      "226/782 [=======>......................] - ETA: 0s - loss: 1.0841 - accuracy: 0.6514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5645 - accuracy: 0.8336\n",
      "782/782 [==============================] - 1s 762us/step - loss: 1.0617 - accuracy: 0.6641\n",
      "374/782 [=============>................] - ETA: 0s - loss: 0.5510 - accuracy: 0.8326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5560 - accuracy: 0.8338\n",
      "540/782 [===================>..........] - ETA: 0s - loss: 0.5276 - accuracy: 0.8429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5225 - accuracy: 0.8455\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.2206 - accuracy: 0.6150\n",
      "1186/1563 [=====================>........] - ETA: 0s - loss: 1.2028 - accuracy: 0.6148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.2283 - accuracy: 0.6079\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1911 - accuracy: 0.6203\n",
      "782/782 [==============================] - 1s 737us/step - loss: 1.3626 - accuracy: 0.6015\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1760 - accuracy: 0.6329\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1372 - accuracy: 0.6443\n",
      "782/782 [==============================] - 1s 816us/step - loss: 1.1007 - accuracy: 0.6741\n",
      " 73/782 [=>............................] - ETA: 0s - loss: 1.1629 - accuracy: 0.6490 6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 866us/step - loss: 1.1035 - accuracy: 0.6622\n",
      " 123/1563 [=>............................] - ETA: 1s - loss: 1.8810 - accuracy: 0.4858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 978us/step - loss: 1.0807 - accuracy: 0.6586\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1492 - accuracy: 0.6522\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2506 - accuracy: 0.6071\n",
      " 409/1563 [======>.......................] - ETA: 1s - loss: 1.5351 - accuracy: 0.5546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3092 - accuracy: 0.6066\n",
      " 695/1563 [============>.................] - ETA: 1s - loss: 1.3436 - accuracy: 0.6045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 885us/step - loss: 1.2213 - accuracy: 0.6003\n",
      " 893/1563 [================>.............] - ETA: 1s - loss: 1.3309 - accuracy: 0.6090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 934us/step - loss: 1.1171 - accuracy: 0.6773\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2779 - accuracy: 0.6138\n",
      "1349/1563 [========================>.....] - ETA: 0s - loss: 1.2986 - accuracy: 0.6191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2904 - accuracy: 0.6227\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3885 - accuracy: 0.6064\n",
      "782/782 [==============================] - 1s 832us/step - loss: 1.1986 - accuracy: 0.6512\n",
      "619/782 [======================>.......] - ETA: 0s - loss: 1.2807 - accuracy: 0.6143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 880us/step - loss: 1.2759 - accuracy: 0.6168\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3139 - accuracy: 0.6113\n",
      "782/782 [==============================] - 1s 862us/step - loss: 1.5865 - accuracy: 0.5776\n",
      " 238/1563 [===>..........................] - ETA: 1s - loss: 1.4816 - accuracy: 0.5674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3301 - accuracy: 0.5972\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.4106 - accuracy: 0.6273\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3772 - accuracy: 0.6112\n",
      " 53/782 [=>............................] - ETA: 0s - loss: 1.3177 - accuracy: 0.6462 6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 929us/step - loss: 1.1218 - accuracy: 0.6583\n",
      " 192/1563 [==>...........................] - ETA: 2s - loss: 1.8443 - accuracy: 0.5223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3198 - accuracy: 0.6093\n",
      "782/782 [==============================] - 1s 992us/step - loss: 1.2676 - accuracy: 0.6564\n",
      " 188/1563 [==>...........................] - ETA: 1s - loss: 1.7282 - accuracy: 0.5148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 889us/step - loss: 1.1782 - accuracy: 0.6518\n",
      " 569/1563 [=========>....................] - ETA: 1s - loss: 1.4232 - accuracy: 0.5784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1873 - accuracy: 0.6419\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2407 - accuracy: 0.6292\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2756 - accuracy: 0.6267\n",
      "782/782 [==============================] - 1s 955us/step - loss: 1.1216 - accuracy: 0.6620\n",
      "1280/1563 [=======================>......] - ETA: 0s - loss: 1.3799 - accuracy: 0.6117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1657 - accuracy: 0.6591\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1621 - accuracy: 0.6256\n",
      "1150/1563 [=====================>........] - ETA: 0s - loss: 1.4366 - accuracy: 0.5986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.3614 - accuracy: 0.6166\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.3489 - accuracy: 0.6097\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.3922 - accuracy: 0.6123\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.2823 - accuracy: 0.6536\n",
      "332/782 [===========>..................] - ETA: 0s - loss: 1.1675 - accuracy: 0.6623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 981us/step - loss: 1.2394 - accuracy: 0.6375\n",
      "782/782 [==============================] - 1s 936us/step - loss: 1.1439 - accuracy: 0.6697\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6685 - accuracy: 0.5575\n",
      " 40/782 [>.............................] - ETA: 0s - loss: 1.3817 - accuracy: 0.6227 7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/782 [=======>......................] - ETA: 0s - loss: 1.3769 - accuracy: 0.629812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.3532 - accuracy: 0.6317\n",
      "1447/1563 [==========================>...] - ETA: 0s - loss: 1.2514 - accuracy: 0.6216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.2403 - accuracy: 0.6248\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.5259 - accuracy: 0.5840\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.2110 - accuracy: 0.6308\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1209 - accuracy: 0.6670\n",
      " 541/1563 [=========>....................] - ETA: 2s - loss: 1.6488 - accuracy: 0.5704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.4074 - accuracy: 0.6454\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.0512 - accuracy: 0.6788\n",
      "1413/1563 [==========================>...] - ETA: 0s - loss: 1.2130 - accuracy: 0.6375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.2109 - accuracy: 0.6389\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.5815 - accuracy: 0.5866\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1137 - accuracy: 0.6887\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5006 - accuracy: 0.6058\n",
      "782/782 [==============================] - 1s 983us/step - loss: 1.5292 - accuracy: 0.6000\n",
      "456/782 [================>.............] - ETA: 0s - loss: 1.1713 - accuracy: 0.6810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6476 - accuracy: 0.5896\n",
      "599/782 [=====================>........] - ETA: 0s - loss: 1.1667 - accuracy: 0.683095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1632 - accuracy: 0.6834\n",
      "1003/1563 [==================>...........] - ETA: 1s - loss: 1.4904 - accuracy: 0.5968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.2162 - accuracy: 0.6909\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.2193 - accuracy: 0.6297\n",
      " 510/1563 [========>.....................] - ETA: 2s - loss: 1.8520 - accuracy: 0.5559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4543 - accuracy: 0.6074\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5971 - accuracy: 0.5944\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.0515 - accuracy: 0.6802\n",
      "177/782 [=====>........................] - ETA: 0s - loss: 1.9239 - accuracy: 0.5228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.2436 - accuracy: 0.6438\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9506 - accuracy: 0.5224\n",
      "1162/1563 [=====================>........] - ETA: 1s - loss: 1.2595 - accuracy: 0.6353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 401/1563 [======>.......................] - ETA: 3s - loss: 1.7921 - accuracy: 0.5355    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6077 - accuracy: 0.5957\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2248 - accuracy: 0.6398\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5400 - accuracy: 0.5873\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7728 - accuracy: 0.5852\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5281 - accuracy: 0.6068\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1521 - accuracy: 0.6435\n",
      "1202/1563 [======================>.......] - ETA: 1s - loss: 1.5258 - accuracy: 0.5923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1675 - accuracy: 0.6748\n",
      "1357/1563 [=========================>....] - ETA: 0s - loss: 1.5083 - accuracy: 0.5972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4850 - accuracy: 0.6041\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.4957 - accuracy: 0.6316\n",
      "1531/1563 [============================>.] - ETA: 0s - loss: 1.6893 - accuracy: 0.5959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6808 - accuracy: 0.5970\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9058 - accuracy: 0.5822\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.0944 - accuracy: 0.6940\n",
      " 826/1563 [==============>...............] - ETA: 2s - loss: 2.2576 - accuracy: 0.4954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7553 - accuracy: 0.5571\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.6878 - accuracy: 0.6364\n",
      " 936/1563 [================>.............] - ETA: 1s - loss: 1.8744 - accuracy: 0.5614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 298/1563 [====>.........................] - ETA: 1s - loss: 1.0083 - accuracy: 0.6813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7854 - accuracy: 0.7575\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7940 - accuracy: 0.7593\n",
      "782/782 [==============================] - 1s 734us/step - loss: 0.6984 - accuracy: 0.7838\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8002 - accuracy: 0.5896\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0609 - accuracy: 0.5283\n",
      "  1/782 [..............................] - ETA: 39s - loss: 2.0433 - accuracy: 0.56255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 798us/step - loss: 0.7068 - accuracy: 0.7900\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8146 - accuracy: 0.5806\n",
      "1549/1563 [============================>.] - ETA: 0s - loss: 0.7902 - accuracy: 0.7589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7889 - accuracy: 0.7594\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.9518 - accuracy: 0.5961\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8821 - accuracy: 0.5689\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7311 - accuracy: 0.7760\n",
      "431/782 [===============>..............] - ETA: 0s - loss: 1.2586 - accuracy: 0.6644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 805us/step - loss: 0.6999 - accuracy: 0.7861\n",
      "194/782 [======>.......................] - ETA: 0s - loss: 0.6455 - accuracy: 0.805706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.2506 - accuracy: 0.6701\n",
      "782/782 [==============================] - 1s 915us/step - loss: 0.6530 - accuracy: 0.8037\n",
      " 210/1563 [===>..........................] - ETA: 1s - loss: 0.9947 - accuracy: 0.6793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7426 - accuracy: 0.7733\n",
      "500/782 [==================>...........] - ETA: 0s - loss: 0.6487 - accuracy: 0.8069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7301 - accuracy: 0.7769\n",
      "782/782 [==============================] - 1s 916us/step - loss: 0.6476 - accuracy: 0.8062\n",
      "1088/1563 [===================>..........] - ETA: 0s - loss: 0.7530 - accuracy: 0.7688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 837us/step - loss: 0.6180 - accuracy: 0.8162\n",
      "1307/1563 [========================>.....] - ETA: 0s - loss: 0.7311 - accuracy: 0.7759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7150 - accuracy: 0.7809\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7044 - accuracy: 0.7842\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7098 - accuracy: 0.7829\n",
      "782/782 [==============================] - 1s 873us/step - loss: 0.6324 - accuracy: 0.8063\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6985 - accuracy: 0.7869\n",
      "782/782 [==============================] - 1s 848us/step - loss: 0.6249 - accuracy: 0.8094\n",
      "1229/1563 [======================>.......] - ETA: 0s - loss: 0.7234 - accuracy: 0.7758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 849us/step - loss: 0.6085 - accuracy: 0.8144\n",
      " 105/1563 [=>............................] - ETA: 2s - loss: 1.1187 - accuracy: 0.6488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 940us/step - loss: 0.6024 - accuracy: 0.8181\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6978 - accuracy: 0.7852\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.7033 - accuracy: 0.7843\n",
      "782/782 [==============================] - 1s 764us/step - loss: 0.6091 - accuracy: 0.8180\n",
      " 850/1563 [===============>..............] - ETA: 1s - loss: 0.7630 - accuracy: 0.7651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6946 - accuracy: 0.7868\n",
      " 164/1563 [==>...........................] - ETA: 1s - loss: 0.9777 - accuracy: 0.6848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 940us/step - loss: 0.6138 - accuracy: 0.8111\n",
      "1272/1563 [=======================>......] - ETA: 0s - loss: 0.7129 - accuracy: 0.7807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 919us/step - loss: 0.5855 - accuracy: 0.8233\n",
      "1506/1563 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.7869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6928 - accuracy: 0.7879\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6988 - accuracy: 0.7839\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6920 - accuracy: 0.7890\n",
      "782/782 [==============================] - 1s 922us/step - loss: 0.5955 - accuracy: 0.8210\n",
      "782/782 [==============================] - 1s 811us/step - loss: 0.6006 - accuracy: 0.8222\n",
      "1223/1563 [======================>.......] - ETA: 0s - loss: 0.7144 - accuracy: 0.7788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 991us/step - loss: 0.6301 - accuracy: 0.8081\n",
      "1540/1563 [============================>.] - ETA: 0s - loss: 0.6902 - accuracy: 0.7866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6893 - accuracy: 0.7870\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6903 - accuracy: 0.7886\n",
      "782/782 [==============================] - 1s 916us/step - loss: 0.5875 - accuracy: 0.8245\n",
      "1304/1563 [========================>.....] - ETA: 0s - loss: 0.7046 - accuracy: 0.7820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6848 - accuracy: 0.7912\n",
      "782/782 [==============================] - 1s 896us/step - loss: 0.6294 - accuracy: 0.8093\n",
      " 179/1563 [==>...........................] - ETA: 2s - loss: 1.0338 - accuracy: 0.6674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6859 - accuracy: 0.7877\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6170 - accuracy: 0.8116\n",
      "1359/1563 [=========================>....] - ETA: 0s - loss: 0.7075 - accuracy: 0.7825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 921us/step - loss: 0.5882 - accuracy: 0.8235\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6905 - accuracy: 0.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6904 - accuracy: 0.7887\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6820 - accuracy: 0.7901\n",
      "782/782 [==============================] - 1s 967us/step - loss: 0.5883 - accuracy: 0.8193\n",
      "102/782 [==>...........................] - ETA: 0s - loss: 0.5817 - accuracy: 0.8220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6090 - accuracy: 0.8124\n",
      " 155/1563 [=>............................] - ETA: 2s - loss: 1.0418 - accuracy: 0.6700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5870 - accuracy: 0.8256\n",
      " 319/1563 [=====>........................] - ETA: 2s - loss: 0.8844 - accuracy: 0.7190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6900 - accuracy: 0.7882\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6861 - accuracy: 0.7894\n",
      "782/782 [==============================] - 1s 935us/step - loss: 0.5989 - accuracy: 0.8178\n",
      "1494/1563 [===========================>..] - ETA: 0s - loss: 0.6911 - accuracy: 0.7865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6872 - accuracy: 0.7879\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6010 - accuracy: 0.8172\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6891 - accuracy: 0.7883\n",
      " 330/1563 [=====>........................] - ETA: 2s - loss: 0.8880 - accuracy: 0.7239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6011 - accuracy: 0.8169\n",
      "724/782 [==========================>...] - ETA: 0s - loss: 0.5833 - accuracy: 0.8226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5864 - accuracy: 0.8227\n",
      " 457/1563 [=======>......................] - ETA: 2s - loss: 0.8288 - accuracy: 0.7431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6877 - accuracy: 0.7887\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6812 - accuracy: 0.7920\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6868 - accuracy: 0.7891\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5702 - accuracy: 0.8276\n",
      "1294/1563 [=======================>......] - ETA: 0s - loss: 0.7068 - accuracy: 0.7822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6147 - accuracy: 0.8205\n",
      "1453/1563 [==========================>...] - ETA: 0s - loss: 0.6971 - accuracy: 0.7849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6032 - accuracy: 0.8153\n",
      " 110/1563 [=>............................] - ETA: 2s - loss: 1.1420 - accuracy: 0.6415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6896 - accuracy: 0.7878\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6879 - accuracy: 0.7879\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.8218\n",
      " 482/1563 [========>.....................] - ETA: 2s - loss: 0.8167 - accuracy: 0.7484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6903 - accuracy: 0.7909\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6123 - accuracy: 0.8131\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6865 - accuracy: 0.7887\n",
      " 925/1563 [================>.............] - ETA: 1s - loss: 0.7371 - accuracy: 0.7743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5812 - accuracy: 0.8259\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6588 - accuracy: 0.7974\n",
      " 445/1563 [=======>......................] - ETA: 2s - loss: 0.8475 - accuracy: 0.7396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6859 - accuracy: 0.7900\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6865 - accuracy: 0.7907\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6929 - accuracy: 0.7889\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5803 - accuracy: 0.8283\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6212 - accuracy: 0.8120\n",
      " 635/1563 [===========>..................] - ETA: 2s - loss: 0.7755 - accuracy: 0.7588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5770 - accuracy: 0.8254\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6896 - accuracy: 0.7899\n",
      " 847/1563 [===============>..............] - ETA: 1s - loss: 0.7440 - accuracy: 0.7698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6824 - accuracy: 0.7914\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6017 - accuracy: 0.8194\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6969 - accuracy: 0.7878\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6014 - accuracy: 0.8217\n",
      "1547/1563 [============================>.] - ETA: 0s - loss: 0.6914 - accuracy: 0.7873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6908 - accuracy: 0.7875\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6120 - accuracy: 0.8141\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6267 - accuracy: 0.8064\n",
      "1057/1563 [===================>..........] - ETA: 1s - loss: 0.7235 - accuracy: 0.7768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6945 - accuracy: 0.7859\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6943 - accuracy: 0.7872\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.0427 - accuracy: 0.7052\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6822 - accuracy: 0.7902\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.7950\n",
      "782/782 [==============================] - 1s 726us/step - loss: 0.8106 - accuracy: 0.7618\n",
      "1031/1563 [==================>...........] - ETA: 1s - loss: 0.7293 - accuracy: 0.7734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5684 - accuracy: 0.8283\n",
      "1097/1563 [====================>.........] - ETA: 1s - loss: 0.7221 - accuracy: 0.7765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.0275 - accuracy: 0.7066\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.0424 - accuracy: 0.7041\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6055 - accuracy: 0.8170 \n",
      "782/782 [==============================] - 1s 794us/step - loss: 0.8076 - accuracy: 0.7641\n",
      "782/782 [==============================] - 1s 746us/step - loss: 0.8101 - accuracy: 0.7630\n",
      "1373/1563 [=========================>....] - ETA: 0s - loss: 0.6994 - accuracy: 0.7851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 141/1563 [=>............................] - ETA: 1s - loss: 1.5244 - accuracy: 0.5601"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6870 - accuracy: 0.7890\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.9357 - accuracy: 0.7299\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.9378 - accuracy: 0.7280\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.9377 - accuracy: 0.7278\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6324 - accuracy: 0.8076\n",
      "1202/1563 [======================>.......] - ETA: 0s - loss: 0.9390 - accuracy: 0.7264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 685us/step - loss: 0.7515 - accuracy: 0.7807\n",
      "782/782 [==============================] - 1s 666us/step - loss: 0.7499 - accuracy: 0.7770\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8922 - accuracy: 0.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8968 - accuracy: 0.7380\n",
      "643/782 [=======================>......] - ETA: 0s - loss: 0.7453 - accuracy: 0.778268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8967 - accuracy: 0.7379\n",
      "782/782 [==============================] - 1s 802us/step - loss: 0.7435 - accuracy: 0.7797\n",
      " 225/1563 [===>..........................] - ETA: 2s - loss: 1.2937 - accuracy: 0.6267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 939us/step - loss: 0.7329 - accuracy: 0.7854\n",
      "782/782 [==============================] - 1s 943us/step - loss: 0.7226 - accuracy: 0.7845\n",
      "782/782 [==============================] - 1s 895us/step - loss: 0.7204 - accuracy: 0.7895\n",
      " 460/1563 [=======>......................] - ETA: 1s - loss: 1.1029 - accuracy: 0.6793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 932/1563 [================>.............] - ETA: 0s - loss: 0.9616 - accuracy: 0.7185  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8817 - accuracy: 0.7388\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8664 - accuracy: 0.7444\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8747 - accuracy: 0.7433\n",
      "782/782 [==============================] - 1s 833us/step - loss: 0.7153 - accuracy: 0.7852\n",
      "782/782 [==============================] - 1s 866us/step - loss: 0.7112 - accuracy: 0.7919\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8605 - accuracy: 0.7468\n",
      "1295/1563 [=======================>......] - ETA: 0s - loss: 0.8869 - accuracy: 0.7395"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366/1563 [=========================>....] - ETA: 0s - loss: 0.8791 - accuracy: 0.7410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.7102 - accuracy: 0.7928\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8594 - accuracy: 0.7463\n",
      " 317/1563 [=====>........................] - ETA: 2s - loss: 1.1401 - accuracy: 0.6628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.7000 - accuracy: 0.7916\n",
      "782/782 [==============================] - 1s 802us/step - loss: 0.7039 - accuracy: 0.7953\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8651 - accuracy: 0.7422\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8420 - accuracy: 0.7509\n",
      "164/782 [=====>........................] - ETA: 0s - loss: 0.7064 - accuracy: 0.7919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6998 - accuracy: 0.7939\n",
      "782/782 [==============================] - 1s 935us/step - loss: 0.6845 - accuracy: 0.7941\n",
      " 541/1563 [=========>....................] - ETA: 1s - loss: 0.9830 - accuracy: 0.7075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 622/1563 [==========>...................] - ETA: 1s - loss: 0.9584 - accuracy: 0.7155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8459 - accuracy: 0.7499\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8538 - accuracy: 0.7500\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8386 - accuracy: 0.7526\n",
      "782/782 [==============================] - 1s 969us/step - loss: 0.7029 - accuracy: 0.7960\n",
      "140/782 [====>.........................] - ETA: 0s - loss: 0.7005 - accuracy: 0.792069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6876 - accuracy: 0.8004\n",
      "782/782 [==============================] - 1s 971us/step - loss: 0.6933 - accuracy: 0.7934\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8347 - accuracy: 0.7519\n",
      "128/782 [===>..........................] - ETA: 0s - loss: 0.6832 - accuracy: 0.804731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8440 - accuracy: 0.7516\n",
      "782/782 [==============================] - 1s 937us/step - loss: 0.6925 - accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425/1563 [==========================>...] - ETA: 0s - loss: 0.8441 - accuracy: 0.7501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8313 - accuracy: 0.7534\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6952 - accuracy: 0.7980\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8307 - accuracy: 0.7543\n",
      "507/782 [==================>...........] - ETA: 0s - loss: 0.6901 - accuracy: 0.7983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 990us/step - loss: 0.6767 - accuracy: 0.7975\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.7980\n",
      " 895/1563 [================>.............] - ETA: 1s - loss: 0.9118 - accuracy: 0.7271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  80/1563 [>.............................] - ETA: 1s - loss: 1.4453 - accuracy: 0.5547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8336 - accuracy: 0.7519\n",
      "782/782 [==============================] - 1s 980us/step - loss: 0.6758 - accuracy: 0.8035\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8321 - accuracy: 0.7536\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8249 - accuracy: 0.7567\n",
      "1002/1563 [==================>...........] - ETA: 1s - loss: 0.8845 - accuracy: 0.7382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8358 - accuracy: 0.7524\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6775 - accuracy: 0.8016\n",
      "1049/1563 [===================>..........] - ETA: 1s - loss: 0.8819 - accuracy: 0.7386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6824 - accuracy: 0.8002\n",
      "1205/1563 [======================>.......] - ETA: 0s - loss: 0.8646 - accuracy: 0.7440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6751 - accuracy: 0.7999\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8303 - accuracy: 0.7546\n",
      "1360/1563 [=========================>....] - ETA: 0s - loss: 0.8440 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8200 - accuracy: 0.7550\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8266 - accuracy: 0.7554\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.7148 - accuracy: 0.7839\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6670 - accuracy: 0.8063\n",
      "250/782 [========>.....................] - ETA: 0s - loss: 0.6949 - accuracy: 0.7933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6788 - accuracy: 0.8005\n",
      " 875/1563 [===============>..............] - ETA: 1s - loss: 0.9107 - accuracy: 0.7306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8204 - accuracy: 0.7576\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8210 - accuracy: 0.7538\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.7898\n",
      "305/782 [==========>...................] - ETA: 0s - loss: 0.6922 - accuracy: 0.7972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8269 - accuracy: 0.7536\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.7991\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8172 - accuracy: 0.7580\n",
      "1036/1563 [==================>...........] - ETA: 1s - loss: 0.8741 - accuracy: 0.7367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6798 - accuracy: 0.8048\n",
      " 862/1563 [===============>..............] - ETA: 1s - loss: 0.8961 - accuracy: 0.7344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6819 - accuracy: 0.7948\n",
      " 430/1563 [=======>......................] - ETA: 2s - loss: 1.0081 - accuracy: 0.6972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8221 - accuracy: 0.7556\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8162 - accuracy: 0.7551\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8184 - accuracy: 0.7570\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6783 - accuracy: 0.7987\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6902 - accuracy: 0.7969\n",
      " 476/1563 [========>.....................] - ETA: 2s - loss: 0.9726 - accuracy: 0.7083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6697 - accuracy: 0.7986\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8147 - accuracy: 0.7574\n",
      " 819/1563 [==============>...............] - ETA: 2s - loss: 0.8999 - accuracy: 0.7320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8215 - accuracy: 0.7555\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.7936\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8147 - accuracy: 0.7574\n",
      " 868/1563 [===============>..............] - ETA: 1s - loss: 0.8974 - accuracy: 0.7334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6553 - accuracy: 0.8090\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8145 - accuracy: 0.7568\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.6828 - accuracy: 0.7950\n",
      "782/782 [==============================] - 1s 992us/step - loss: 0.6718 - accuracy: 0.8047\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8225 - accuracy: 0.7550\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8161 - accuracy: 0.7592\n",
      "782/782 [==============================] - 1s 832us/step - loss: 0.6709 - accuracy: 0.8037\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8074 - accuracy: 0.7585\n",
      "782/782 [==============================] - 1s 806us/step - loss: 0.6786 - accuracy: 0.7946\n",
      "782/782 [==============================] - 1s 670us/step - loss: 0.6640 - accuracy: 0.8049\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.8193 - accuracy: 0.7568\n",
      "782/782 [==============================] - 0s 521us/step - loss: 0.6677 - accuracy: 0.8054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344/2344 [==============================] - 2s 896us/step - loss: 0.6244 - accuracy: 0.8146\n",
      "Best: 0.8422533472379049 using {'activation': 'relu', 'learning_rate': 0.001, 'units': 384}\n",
      "Means: 0.2595333407322566, Stdev: 0.014511287003110076 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 32}\n",
      "Means: 0.2139999916156133, Stdev: 0.07359853941055831 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 64}\n",
      "Means: 0.23085332910219827, Stdev: 0.024630412461728906 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 96}\n",
      "Means: 0.28726667165756226, Stdev: 0.03420459976409997 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 128}\n",
      "Means: 0.2630266696214676, Stdev: 0.08953784752345452 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 160}\n",
      "Means: 0.24593332906564078, Stdev: 0.06594774122002116 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 192}\n",
      "Means: 0.3206266661485036, Stdev: 0.012421760595619738 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 224}\n",
      "Means: 0.2508133302132289, Stdev: 0.018620736175132675 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 256}\n",
      "Means: 0.27538666625817615, Stdev: 0.036378518707950995 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 288}\n",
      "Means: 0.27801332871119183, Stdev: 0.01779360821890598 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 320}\n",
      "Means: 0.2608399987220764, Stdev: 0.04251132857631805 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 352}\n",
      "Means: 0.24340000251928964, Stdev: 0.05271102374501827 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 384}\n",
      "Means: 0.28495999177296955, Stdev: 0.010957421178503573 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 416}\n",
      "Means: 0.29922666152318317, Stdev: 0.0206977024501931 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 448}\n",
      "Means: 0.31457332770029706, Stdev: 0.02247172387185059 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 480}\n",
      "Means: 0.7823466658592224, Stdev: 0.00619285158650388 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 32}\n",
      "Means: 0.8001733422279358, Stdev: 0.009047766855307242 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 64}\n",
      "Means: 0.8002266685167948, Stdev: 0.006852545262627029 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 96}\n",
      "Means: 0.8021999796231588, Stdev: 0.005037243328970146 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 128}\n",
      "Means: 0.8074000080426534, Stdev: 0.001432568401077542 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 160}\n",
      "Means: 0.7990666627883911, Stdev: 0.009854467092721156 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 192}\n",
      "Means: 0.8075999816258749, Stdev: 0.0027284232279061755 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 224}\n",
      "Means: 0.8032666643460592, Stdev: 0.0001359558937398894 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 256}\n",
      "Means: 0.8077733119328817, Stdev: 0.0017676565108053156 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 288}\n",
      "Means: 0.8005866607030233, Stdev: 0.0008655207308573687 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 320}\n",
      "Means: 0.8017599781354269, Stdev: 0.0025338210485124782 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 352}\n",
      "Means: 0.8020400007565817, Stdev: 0.006808080018192864 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 384}\n",
      "Means: 0.8012533386548361, Stdev: 0.004784878619491011 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 416}\n",
      "Means: 0.8037999868392944, Stdev: 0.0019319098639058894 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 448}\n",
      "Means: 0.8024400075276693, Stdev: 0.0017663483291625785 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 480}\n",
      "Means: 0.790013333161672, Stdev: 0.004068933369560877 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 32}\n",
      "Means: 0.809879998366038, Stdev: 0.002065336772942129 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 64}\n",
      "Means: 0.8190400004386902, Stdev: 0.0007483282151145294 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 96}\n",
      "Means: 0.8235200047492981, Stdev: 0.001532937048843216 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 128}\n",
      "Means: 0.8298533161481222, Stdev: 0.0023352036845926795 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 160}\n",
      "Means: 0.8284800251324972, Stdev: 0.0005455295097382721 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 192}\n",
      "Means: 0.8306133349736532, Stdev: 0.0029484947422900964 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 224}\n",
      "Means: 0.8327733278274536, Stdev: 0.0008698265615424001 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 256}\n",
      "Means: 0.8386533260345459, Stdev: 0.0008698375253460719 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 288}\n",
      "Means: 0.8382933338483175, Stdev: 0.0006790956901904005 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 320}\n",
      "Means: 0.8396133383115133, Stdev: 0.0024460771687254052 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 352}\n",
      "Means: 0.8422533472379049, Stdev: 0.001853956763163645 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 384}\n",
      "Means: 0.8409333427747091, Stdev: 0.0012667259520143378 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 416}\n",
      "Means: 0.8383733232816061, Stdev: 0.005224079709956785 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 448}\n",
      "Means: 0.8376533389091492, Stdev: 0.0055629668993964175 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 480}\n",
      "Means: 0.6634399890899658, Stdev: 0.023128796182731816 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 32}\n",
      "Means: 0.6465733448664347, Stdev: 0.03214609131926225 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 64}\n",
      "Means: 0.6576666434605917, Stdev: 0.004103245280293312 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 96}\n",
      "Means: 0.642906665802002, Stdev: 0.03197226934121248 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 128}\n",
      "Means: 0.6072133382161459, Stdev: 0.021375683234927542 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 160}\n",
      "Means: 0.6555066704750061, Stdev: 0.002735722790798135 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 192}\n",
      "Means: 0.6488800048828125, Stdev: 0.016532776178092973 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 224}\n",
      "Means: 0.6535999973615011, Stdev: 0.013145616760301739 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 256}\n",
      "Means: 0.6480133334795634, Stdev: 0.014540872935067308 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 288}\n",
      "Means: 0.6558133363723755, Stdev: 0.039673215119108304 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 320}\n",
      "Means: 0.684826652208964, Stdev: 0.004475284816317705 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 352}\n",
      "Means: 0.5838000178337097, Stdev: 0.04958699558319419 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 384}\n",
      "Means: 0.6499866644541422, Stdev: 0.018203642651574103 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 416}\n",
      "Means: 0.6291600068410238, Stdev: 0.05611245900909413 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 448}\n",
      "Means: 0.6116800109545389, Stdev: 0.0427619718413279 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 480}\n",
      "Means: 0.7866400082906088, Stdev: 0.002545802921944421 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 32}\n",
      "Means: 0.8087066809336344, Stdev: 0.005394454669371044 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 64}\n",
      "Means: 0.8100000222524008, Stdev: 0.003329546310482018 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 96}\n",
      "Means: 0.8157066702842712, Stdev: 0.003271931501473209 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 128}\n",
      "Means: 0.8221466541290283, Stdev: 0.0009308527021839 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 160}\n",
      "Means: 0.8139733274777731, Stdev: 0.007472637985861365 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 192}\n",
      "Means: 0.818120002746582, Stdev: 0.00495108214158552 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 224}\n",
      "Means: 0.818613330523173, Stdev: 0.005435734123646403 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 256}\n",
      "Means: 0.8189333279927572, Stdev: 0.002653368399311753 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 288}\n",
      "Means: 0.8211333354314169, Stdev: 0.005067044013243884 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 320}\n",
      "Means: 0.8202666640281677, Stdev: 0.00533119107341465 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 352}\n",
      "Means: 0.812559982140859, Stdev: 0.012612914250199931 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 384}\n",
      "Means: 0.8221466739972433, Stdev: 0.0024877918819434883 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 416}\n",
      "Means: 0.8051600058873495, Stdev: 0.007851683047315153 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 448}\n",
      "Means: 0.8175999919573466, Stdev: 0.00847097982835614 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 480}\n",
      "Means: 0.7629866600036621, Stdev: 0.0009152547089189661 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 32}\n",
      "Means: 0.7791333397229513, Stdev: 0.0015900729245908998 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 64}\n",
      "Means: 0.7864800095558167, Stdev: 0.002185054773958339 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 96}\n",
      "Means: 0.7899466753005981, Stdev: 0.003405462053654798 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 128}\n",
      "Means: 0.7935999830563863, Stdev: 0.0014991539770815368 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 160}\n",
      "Means: 0.7968266805013021, Stdev: 0.0026234540873800857 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 192}\n",
      "Means: 0.797106663386027, Stdev: 0.0027771175425359597 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 224}\n",
      "Means: 0.7996399998664856, Stdev: 0.002722372434734732 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 256}\n",
      "Means: 0.8005333344141642, Stdev: 0.0007348936000329504 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 288}\n",
      "Means: 0.7969066699345907, Stdev: 0.009487423280781539 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 320}\n",
      "Means: 0.7978799939155579, Stdev: 0.00618617386691146 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 352}\n",
      "Means: 0.7967866659164429, Stdev: 0.0016180154305934463 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 384}\n",
      "Means: 0.8004000186920166, Stdev: 0.006425030052345879 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 416}\n",
      "Means: 0.801146666208903, Stdev: 0.004335806039487518 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 448}\n",
      "Means: 0.8016400138537089, Stdev: 0.004953012357835612 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 480}\n"
     ]
    }
   ],
   "source": [
    "# save start time \n",
    "start = time()\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=hyper_parameters, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# save end time \n",
    "end = time()\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "THKMZLNv7mNw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0616034626960755"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total run time \n",
    "total_run_time_in_miniutes = (end - start)/60\n",
    "total_run_time_in_miniutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4XgJsrZb7mNx",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'learning_rate': 0.001, 'units': 384}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aYufbSI87mNx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 466us/step - loss: 0.4968 - accuracy: 0.8541\n"
     ]
    }
   ],
   "source": [
    "# because all other optimization approaches are reporting test set score\n",
    "# let's calculate the test set score in this case \n",
    "best_model = grid_result.best_estimator_\n",
    "test_acc = best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BlR-pVwP7mNx",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541200160980225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gj4jJ0Qm7mNx"
   },
   "source": [
    " ### Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "10px3N2q7mNx",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9577db883482c6cded3836e5cfbf5a74",
     "grade": true,
     "grade_id": "cell-eb06d682d2790f6e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Best parameters: 'activation': 'relu', 'learning_rate': 0.001, 'units': 384\n",
    "\n",
    "Best score: 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zu-lBWph7mNq"
   },
   "source": [
    "------\n",
    "## 2.2 Random Search with `keras-tuner`\n",
    "\n",
    "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `RandomSearch` tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# because gridsearching can take a lot of time and we are bench marking 3 different approaches\n",
    "# let's build a simple model to minimize run time \n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a complied keras model ready for keras-tuner gridsearch algorithms \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # hidden layer\n",
    "    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.get('learning_rate')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "id": "8DApqLli7mNq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaff9aae33845f374e15f2381719d83a",
     "grade": false,
     "grade_id": "cell-8c1dfb9b6d12bea2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many unique hyperparameter combinations do we have? \n",
    "# HINT: take the product of the number of possible values for each hyperparameter \n",
    "# save your answer to n_unique_hparam_combos\n",
    "\n",
    "# YOUR CODE HERE\n",
    "n_unique_hparam_combos = 15 * 3 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "id": "m1UKRA597mNq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9d628451e83431e1b52da10eccf2c00",
     "grade": false,
     "grade_id": "cell-1fa83950bb2d5f92",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many of these do we want to randomly sample?\n",
    "# let's pick 25% of n_unique_hparam_combos param combos to sample\n",
    "# save this number to n_param_combos_to_sample\n",
    "\n",
    "# YOUR CODE HERE\n",
    "fraction_to_sample = 0.25\n",
    "n_param_combos_to_sample = int(fraction_to_sample * n_unique_hparam_combos)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TzaNnzoQU4U"
   },
   "source": [
    "### Instantiate a `RandomSearch()` object for your grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Y9PCHLBWQPcb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "random_tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=n_param_combos_to_sample, # number of times to sample the parameter set and build a model \n",
    "            seed=1234,\n",
    "            hyperparameters=hp, # pass in our hyperparameter dictionary\n",
    "            directory='./keras-tuner-trial',\n",
    "            project_name='random_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 609103,
     "status": "ok",
     "timestamp": 1631141924575,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "OGFdv1qE7mNr",
    "outputId": "f4fb1482-c4bc-40cd-c426-d8248e67341f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 Complete [00h 00m 08s]\n",
      "val_accuracy: 0.8167200088500977\n",
      "\n",
      "Best val_accuracy So Far: 0.8727999925613403\n",
      "Total elapsed time: 00h 02m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    " # take note of Total elapsed time in print out -- took ~10 minutes without GPU\n",
    "random_tuner.search(X_train, y_train,\n",
    "                    epochs=3,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1631144598023,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "zNBUhIe97mNr",
    "outputId": "a12fb52d-eec7-4b72-a2d0-cfb8482ade48",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras-tuner-trial/random_search\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8727999925613403\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.871999979019165\n",
      "\n",
      "Trial 18 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8681600093841553\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.860319972038269\n",
      "\n",
      "Trial 19 summary\n",
      "Hyperparameters:\n",
      "units: 192\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8545200228691101\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 96\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8407999873161316\n",
      "\n",
      "Trial 16 summary\n",
      "Hyperparameters:\n",
      "units: 448\n",
      "learning_rate: 0.01\n",
      "activation: sigmoid\n",
      "Score: 0.8319200277328491\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 224\n",
      "learning_rate: 0.01\n",
      "activation: sigmoid\n",
      "Score: 0.8303200006484985\n",
      "\n",
      "Trial 10 summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "learning_rate: 0.01\n",
      "activation: relu\n",
      "Score: 0.8176400065422058\n",
      "\n",
      "Trial 21 summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "learning_rate: 0.01\n",
      "activation: relu\n",
      "Score: 0.8167200088500977\n"
     ]
    }
   ],
   "source": [
    "# identify the best score and hyperparamter (should be at the top since scores are ranked)\n",
    "random_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRpQVXBE7mNr",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    " ### Results\n",
    " \n",
    "Identify and write the the best performing hyperparameter combination and model score. \n",
    "Note that because this is Random Search, multiple runs might have slighly different outcomes. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "aQjMc84c7mNs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f084b5d373f8589a1de8d6d4473b974a",
     "grade": true,
     "grade_id": "cell-5527738b6382c164",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Best Hyperparameters:\n",
    "\n",
    "units: 384\n",
    "\n",
    "learning_rate: 0.001\n",
    "\n",
    "activation: relu\n",
    "\n",
    "Score: 0.873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXjW7eYA7mNs"
   },
   "source": [
    "------\n",
    "## 2.3 Bayesian Optimization with `keras-tuner`\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif)\n",
    "\n",
    "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `BayesianOptimization` tuner.\n",
    "\n",
    "Pay special attention to these `BayesianOptimization` parameters: `num_initial_points` and `beta`. \n",
    "\n",
    "`num_initial_points`: \n",
    "\n",
    "Number of randomly selected hyperparameter combinations to try before applying bayesian probability to determine liklihood of which param combo to try next based on expected improvement\n",
    "\n",
    "\n",
    "`beta`: \n",
    "\n",
    "Larger values means more willing to explore new hyperparameter combinations (analogous to searching for the global minimum in Gradient Descent), smaller values means that it is less willing to try new hyperparameter combinations (analogous to getting stuck in a local minimum in Gradient Descent). \n",
    "\n",
    "As a start, error on the side of larger values. What defines a small or large value you ask? That question would pull us into the mathematical intricacies of Bayesian Optimization and Gaussian Processes. For simplicity, notice that the default value is 2.6 and work from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "_NXjQBn47mNs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we know that 24 samples is about 25% of 96 possible hyper-parameter combos\n",
    "# let's set up a run with the same parameters we used for RandomSearch() so the comparison will be aplles-to-apples\n",
    "# feel free to play with any of these numbers later\n",
    "max_trials=24\n",
    "num_initial_points=5\n",
    "beta=5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhZNIJZ4RS5Y"
   },
   "source": [
    "#### Instantiate a `BayesianOptimization()` object for your grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1631144696927,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "33joO_J97mNs",
    "outputId": "9241d1ca-eed3-433f-9188-e854e808afd1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner = BayesianOptimization(\n",
    "                    build_model,\n",
    "                    objective='val_accuracy',\n",
    "                    max_trials=max_trials,\n",
    "                    hyperparameters=hp, # pass in our hyperparameter dictionary\n",
    "                    num_initial_points=num_initial_points, \n",
    "                    beta=beta, \n",
    "                    seed=1234,\n",
    "                    directory='./keras-tuner-trial',\n",
    "                    project_name='bayesian_optimization_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 185918,
     "status": "ok",
     "timestamp": 1631144887308,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "h9AM5Pdj7mNt",
    "outputId": "6ca1e102-3836-4d46-c535-572f8a7f085c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 Complete [00h 00m 09s]\n",
      "val_accuracy: 0.8737999796867371\n",
      "\n",
      "Best val_accuracy So Far: 0.8745599985122681\n",
      "Total elapsed time: 00h 03m 01s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.search(X_train, y_train,\n",
    "               epochs=3,\n",
    "               validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1631144887310,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "FJcHC8d87mNt",
    "outputId": "a610cf67-6251-4976-9409-30a57ed02be9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras-tuner-trial/bayesian_optimization_4\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 22 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8745599985122681\n",
      "\n",
      "Trial 21 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.873960018157959\n",
      "\n",
      "Trial 23 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8737999796867371\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8720800280570984\n",
      "\n",
      "Trial 20 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8720399737358093\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units: 448\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8719199895858765\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8678799867630005\n",
      "\n",
      "Trial 19 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8670399785041809\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8627600073814392\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.860319972038269\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woo9D9AU7mNu"
   },
   "source": [
    " ### Results\n",
    " \n",
    "Identify and write the the best performing hyperparameter combination and model score. \n",
    "Note that because this is  Bayesian Optimization, multiple runs might have slighly different outcomes. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "1EXa47mH7mNu",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1badcdca408cdd49bc2e409dca3bac5a",
     "grade": true,
     "grade_id": "cell-ff95600bf745f40f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Best Hyperparameters:\n",
    "units: 512\n",
    "\n",
    "learning_rate: 0.001\n",
    "\n",
    "activation: relu\n",
    "\n",
    "Score: 0.875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOZ5-tJDraFE"
   },
   "source": [
    "We should point out that Gridsearch split the training set internally and created a test set whereas keras-tuner allows us to pass in a test set. This means that the keras-tuner algorithms were using one test set and our skearn GridSearchCV was using a different test set - so this isn't a perfectly exact 1-to-1 comparision but it'll have to do. In order to compensate for this, we did score the best model on the same test set that keras-tuner used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPYChhrC7mNx"
   },
   "source": [
    "_______\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "The spirit of this experiment is to expose you to the idea of benchmarking and comparing the trade-offs of various gridsearch approaches. \n",
    "\n",
    "Even if we did find a way to pass in the original test set into GridSearchCV, we can see that both Random Search and Bayesian Optimization are arguably better alternatives to a brute force grid search when we consider the trade-offs of run time and locating the best performing model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sth1AfwX7mNy"
   },
   "source": [
    "----\n",
    "\n",
    "# Stretch Goals\n",
    "\n",
    "- Feel free to run whatever gridsearch experiments on whatever models you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2APQG9H7mNy"
   },
   "outputs": [],
   "source": [
    "# this is your open playground - be free to explore as you wish "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DS_423_Tune_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
